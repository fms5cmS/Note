并发(Concurrent)：start and end times overlap.是指立即处理多个任务的能力。如：跑步过程中可以停下来系鞋带。并发可以在同一个的硬件上执行。

并行(Parallel)：execute at exactly the same time.是指同时处理多个任务。如：跑步的同时还在听音乐。并行必须是在不同的硬件上执行。

Web 浏览器运行在单核处理器中时，渲染 HTML 和下载文件的进程会交替进行，这是并发；而如果运行在多核处理器上时，这两个进程可能会在不同核上同时运行，这是并行。

一个进程至少包含一个线程，

- 如果一个进程只包含一个线程，那么它里面的所有代码都只会被串行地执行，每个进程的第一个线程会随着该进程的启动而被创建。
- 如果一个进程中包含多个线程，则其中的代码就可以被并发地执行，除了进程的第一个线程外，其他线程都是由进程中已存在的线程创建出来的。

---

- **同步与异步**

**同步：**同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。

**异步：**异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。

同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。

------

- **阻塞和非阻塞**

**阻塞：** 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。

**非阻塞：** 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。



# IPC

IPC（Inter-Process Communication）方法：

- 基于通信：
  - 以数据传送为手段：管道（pipe，传输字节流）、消息队列（message queue，传送结构化的消息对象）
  - 以共享内存为手段：共享内存区（shared memory）
- 基于信号：操作系统的信号（signal）机制（唯一的异步 IPC 方法）
- 基于同步：信号量（semaphore）



## 信号(了解)

在 Linux 系统下，使用 `kill -l` 可以发现，Linux 共支持 62 中信号（编号为 32、33 的信号不存在） ，其中 1~31 的信号为标准信号（不可靠信号），34~64 的信号为实时信号（可靠信号）。

- ctrl + c：发出 SIFINT 信号，强制进程结束
- ctrl + z：发出 SIGTSTP 信号，任务中断，进程挂起
- ctrl + \：发出 SIGQUIT 信号，进程结束和 dump core
- ctrl + d：EOF

对于同一个进程而言，每种标准信号只会被记录并处理一次，且如果发送给某个进程的标准信号的种类有多个，则它们被处理的顺序也是完全不确定的。而实时信号可以解决这两个问题，即多个同种类的实时信号都可以被记录，且可以按信号的发送顺序被处理。

信号的来源有键盘输入、硬件故障、系统函数调用、软件中的非法运算。进程响应信号的方式有三种：忽略、捕捉、执行默认操作。

针对不同种类的标准信号，其默认的操作方式一定是以下操作之一：终止进程、忽略该信号、终止进程并保存内存信息、停止进程、若进程已停止就恢复。

对于大多数标准信号而言，我们可以自定义进程接收到它们后进行怎样的处理。这种自定义信号响应的唯一方法时，进程要告知操作系统内核：当信号到来时，需要执行什么操作。在程序中，这些作为信号响应的自定义操作往往由函数代表。



# 同步

同步的概念就是==共享==，如果不是共享的资源，就没有必要进行同步。同步的目的是为了线程安全。

同步机制应该遵循的基本准则  ：

1. 空闲让进：当无进程处于临界区时，表明临界资源处于空闲状态，允许一个请求进入临界区的进程立即进入临界区，以有效利用临界资源。
2. 忙则等待：当已有进程处于临界区时，表明临界资源正在被访问，因而其他试图进入临界区的进程必须等待，以保证对临界资源的互斥访问 。
3. 有限等待：对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，以免陷入“死等”状态。
4. 让权等待：当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”状态 。

当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。导致竞态条件发生的代码区称作临界区。在临界区中使用适当的同步就可以避免竞态条件。

同步的用途有两个：避免多个线程在同一时刻操作同一数据块；协调多个线程，以避免它们在同一时刻执行同一代码块。

只要多个进程同时对同一个资源进行访问，就很可能互相干扰，这种干扰通常称为**竞态条件(race condition)**。造成竞态条件的根本原因在于进程在进行某些操作时被中断了。

- **原子操作(atomic operation)**：执行过程中**不能被中断**的操作
  - 所有的系统调用都属于原子操作
  - 原子操作只适合细粒度的简单操作
  - 内核只提供和针对二进制位和整数的原子操作，防止一个原子操作的执行总是无法结束但又无法被中断
- **临界区(critical section)**：只能被串行化访问或执行的某个资源或某段代码

相比原子操作，让串行化执行的若干代码形成临界区的做法更通用。

- **互斥(mutual exclusion 简称 mutex)**：保证只有一个进程或线程在临界区内
  - IPC 方法之一的信号量就属于互斥方法



# CAS

CAS(Compare And Swap)

CAS机制当中使用了3个基本操作数：==内存地址V，旧的预期值A，要修改的新值B==。

更新一个变量的时候，==只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B==。 

举例说明：

假设：在内存地址V当中，存储着值为10的变量。 线程一、二：都想要把变量值加一。

对于线程一、二而言。旧的预期值 A=10，要修改的值 B=11；

执行步骤：

1. 线程一先获得内存地址 V 中的数据，操作完成后，还没有提交更新；A=10，B=11
2. 线程二此时抢先一步，把内存地址 V 中的变量更新为 11； V的实际值=11
3. 线程一开始提交更新，首先对 A 和 地址V的实际值进行比较，A != V的实际值（10！=11），更新失败；
4. 线程一重新获取 V的当前值，并重新计算想要修改的新值。此时对线程一来说，A=11，B=12。这个重新尝试的过程被称为==自旋==。 
5. 这次没有其他线程改变 V的实际值，线程一比较后，`A==V`的实际值（11==11）
6. 线程一进行 SWAP，地址V的值变更为12。

ABA问题（一个变量的值从A改成B，又从B改成A）：

```
案例：账户有100元，要提款50，由于ATM机硬件故障，提款操作被同时提交两次，开启两个线程A、B（都是获取当前值
100，要更新为50）。
        理想情况：一个成功，一个失败，存款只被扣一次。
        实际：A执行成功，余额为50；B由于某种原因阻塞。这是有一笔50的汇款，B仍阻塞，C线程执行成功使得余
额从50变为100。B线程恢复运行，由于阻塞前已获得“当前值”100， 并且经过compare检测，此时存款实际值也是100
，所以成功把变量值100更新成了50。
		解决方法：增加版本号。 真正要做到严谨的CAS机制，我们在Compare阶段不仅要比较期望值A和地址V中的
实际值，还要比较变量的版本号是否一致
```

在Java当中，`AtomicStampedReference`类就实现了用版本号做比较的CAS机制。

 参考：

- https://mp.weixin.qq.com/s/f9PYMnpAgS1gAQYPDuCq-w
- https://mp.weixin.qq.com/s/nRnQKhiSUrDKu3mz3vItWg

# 并发通信模型

常用的并发通信模型：

- 线程+共享内存：对线程间共享状态的各种操作都被封装在线程间传递的消息中
  - 发送消息时对状态进行复制，并在消息传递的边界上交出这个状态的所有权
  - 由于需要执行复制操作，所以大多数消息传递的实现在性能上并不优越，但线程中的状态管理工作通常会变得很简单
- 消息机制认为每个并发单元是自包含的、独立的个体，并且都有自己的变量，但在不同并发单元间这些变量不共享。每个并发单元的输入和输出只有一种，那就是消息。不同进程间靠消息来通信，它们不会共享内存。
  - CSP(Communicating Sequential Process)：通过 channel 通讯（松耦合）、Go 中的 channel 是有容量限制的，且独立于处理 goroutine
  - Actor 模式：直接通讯、mailbox 容量无限、接收线程总是被动地处理消息



# 协程 Coroutine

轻量级“线程”，本质上是一种用户态线程，不需要操作系统进行抢占式调度，再真正的视线中寄存于线程中，开销极小。

非抢占式多任务处理，由协程主动交出控制权

编译器/解释器/虚拟机层面的多任务，而不是操作系统层面的

多个协程可能在一个或多个线程上运行，这是通过调度器来决定的

C++ 通过 Boost.Coroutine 库来支持协程的；

Java 不支持协程；

Python 3.5以前通过`yield`关键字实现协程，3.5 加入了 async def 对协程原生支持。



# 并行计算

并发的一个应用是将一个大的计算切分成一些工作单元，调度到不同的 CPU 上同时地计算

- 每个工作单元应该花费大约 100 微秒到 1 毫秒的时间用于计算。如果单元粒度太小，切分问题以及调度子问题的管理开销可能就会太大。如果单元粒度太大，整个计算也许不得不等待一个慢的工作项结束。
  - 这种缓慢可能因为多种原因而产生，比如：调度、其他进程的中断或者糟糕的内存布局。（注意：工作单元的数目是不依赖于CPU的数目的）
- 尽可能减小共享的数据量。并发写操作的代价非常大，特别是如果 goroutine 运行在不同的CPU上。读操作之间的数据共享则通常不会是个问题。
- 数据访问尽量利用良好的局部性。如果数据能保持在缓存中，数据加载和存储将会快得多得多，这对于写操作也格外地重要。

