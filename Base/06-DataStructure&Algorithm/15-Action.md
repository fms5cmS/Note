# Redis

Redis 中的数据类型底层依赖于哪些数据结构？

## list

list 支持存储一组数据。这种数据类型对应两种实现方法：

- 压缩列表(ziplist)
  - Redis 自己涉及的一种数据存储结构，类似数组，通过一片连续内存空间来存储数据，与数组不同的是，它允许存储的数据大小不同，且不支持随机访问，要访问某个元素时需要像链表一样从头开始遍历，但比较省存储空间
  - 存储的数据量较小时可以采用这一实现方式，具体要满足以下两个条件：
    - list 中保存的单个数据(可能是字符串类型)小于 64B
    - list 中数据个数小于 512 个
  - 这种存储结构即节省内存，还可以支持不同类型数据的存储，且由于数据存储在连续的内存空间，读取效率也很高
- 双向循环链表
  - 当无法同时满足上面压缩列表的两个条件时 list 就要通过双向循环链表实现

## hash

hash 用来存储一组数据对，每个数据对又包含键值两部分，也有两种实现方式：

- 压缩列表(同上)
- 散列表
  - 当无法同时满足压缩列表的两个条件时就会使用散列表来实现 hash 类型
  - Redis 使用链表法来解决哈希冲突，Redis 还支持散列表的动态扩容、缩容
  - 数据动态增加后，装载因子会不断变大，为避免散列表性能下降，当装载因子大于 1 时会触发扩容，将其扩大为原来的 2 倍左右
  - 数据动态减少后，为节省内存，当装载因子小于 0.1 时会触发缩容，将其缩小为字典中数据个数的大约 2 倍大小
  - 扩/缩容会涉及大量的数据搬移、哈希值重新计算，会比较耗时，所以 Redis 采用渐进式扩/缩容，将数据的搬移分批进行，避免了大量数据一次性搬移胆汁的服务停顿。

## set

set 用于存储一组不重复的数据，也有两种实现方法：

- 有序数组
  - 同时满足以下两个条件时采用有序数组实现 set：
    - 存储的数据都是整数
    - 存储的数据元素不超过 512 个
- 散列表，不能同时满足以上两个条件时用散列表存储

## zset

有序集合 zset 用于存储一组数据，且每个数据会有一个分值，通过分值的大小会将数据组织成跳表这样的数据结构，以支持快速按分值、分值区间获取数据。

zset 也不仅只有跳表这一种实现方式，当数据量较小时，Redis 会用压缩列表实现 zset，需要同时满足以下两个条件：

- 所有数据大小都小于 64B
- 元素个数小于 128 个

## 数据结构持久化

如何将数据结构持久化到硬盘？主要有两种解决思路：

- 清除原有存储结构，仅将数据存储到硬盘(Redis 所用的方式)
  - 要从磁盘还原数据到内存时，再将数组组织为原来的数据结构
  - 弊端：还原时会消耗较多时间。如将散列表中数据存储到磁盘后要还原时会重新计算每个数据的哈希值，如果数据量很大，耗时就不可忽视了
- 保留原来的存储格式，将数据按照原有格式存储在磁盘中
  - 以散列表为例，可以将散列表的大小、每个数据被散列到的槽的编号等信息都保存在磁盘中，还原时就可以避免重新计算哈希值

# 简单的搜索引擎

搜索引擎主要分为四部分：搜集、分析、索引、查询。

## 搜集

搜集就是利用爬虫爬取网页。

搜索引擎把整个互联网看作数据结构中的有向图，把每个页面看作一个顶点。如果某个页面中包含另一个页面的链接就在两个顶点间连一条有向边。于是就可以利用图的遍历搜索算法来遍历整个互联网中的网页。

搜索引擎采用的是 BFS 策略。先找一些权重较高的网页链接作为种子网页链接，将其放入队列中，爬虫按照 BFS 的策略不停地从队列中取出链接，然后爬取对应网页，解析出网页中包含的其他网页链接，再将其添加到队列中。

会涉及到四个重要文件，其中 links.bin 和 bloom_filter.bin 这两个文件是爬虫自身所用的。doc_raw.bin、doc_id.bin 是作为搜集阶段的成果，供后面的分析、索引、查询用的。具体如下：

- 待爬取网页链接文件：links.bin

在 BFS 爬取页面的过程中，爬虫会不停地解析页面链接，将其放到队列中。队列中的链接可能会多得内存放不下，所以用一个存储在磁盘中的文件(links.bin)来作为 BFS 中的队列。爬虫从 links.bin 文件中，取出链接去爬取对应的页面，等爬取到网页之后，将解析出来的链接，直接存储到 links.bin 文件中。

这种方式存储网页链接，即使机器断电网页链接也不会丢失，重启后可以继续从之前的位置开始爬取。

那么该如何解析页面获取链接？可以把整个页面看作一个大的字符串，我们可以利用字符串匹配算法，在这个大字符串中，搜索这样一个网页标签，然后顺序读取之间的字符串。这其实就是网页链接。

- 网页判重文件：bloom_filter.bin

使用布隆过滤器就可以快速并且非常节省内存地实现网页的判重。可以定期地(如每隔半小时)将布隆过滤器持久化到磁盘中，存储在 bloom_filter.bin 文件中。这样，即便出现机器宕机，也只会丢失布隆过滤器中的部分数据。当机器重启之后，就可以重新读取磁盘中的 bloom_filter.bin 文件，将其恢复到内存中。

- 原始网页存储文件：doc_raw.bin

爬取到网页之后，需要将其存储下来，以备后面离线分析、索引之用。那如何存储海量的原始网页数据呢？

如果把每个网页都存储为一个独立的文件，那磁盘中的文件就会非常多，数量可能会有几千万，甚至上亿。常用的文件系统显然不适合存储如此多的文件。可以把多个网页存储在一个文件中。每个网页之间，通过一定的标识进行分隔，方便后续读取。格式类似于：

```
网页编号 \t 网页大小 \t 网页内容 \r\n
```

当然，文件也不能太大，因为文件系统对文件的大小也有一定的限制。可以设置每个文件的大小不能超过一定的值(如 1GB)。随着越来越多的网页被添加到文件中，文件的大小就会越来越大，当超过 1GB 的时候，就创建一个新的文件，用来存储新爬取的网页。

- 网页链接及其编号的对应文件：doc_id.bin

网页编号实际上就是给每个网页分配一个唯一的 ID，方便后续对网页进行分析、索引。那如何给网页编号呢？

可以按照网页被爬取的先后顺序，从小到大依次编号。具体是这样做的：我们维护一个中心的计数器，每爬取到一个网页之后，就从计数器中拿一个号码，分配给这个网页，然后计数器加一。在存储网页的同时，将网页链接跟编号之间的对应关系，存储在另一个 doc_id.bin 文件中。

## 分析

分析主要负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作。

1. 抽取网页文本信息
   1. 去掉 JavaScript 代码、CSS 格式以及下拉框(用户不操作是看不到的)中的内容
      - 可以利用 AC 自动机这种多模式串匹配算法，在网页这个大字符串中，一次性查找对应的起始、结束标签，这期间遍历到的字符串连带标签都应删除
   2. 去掉所有 HTML 标签。这一步也是通过字符串匹配算法来实现的
2. 分词并创建临时索引
   - 对于英文网页来说，分词非常简单。只需要通过空格、标点符号等分隔符，将每个单词分割开来就可以了
   - 中文分词则较为麻烦，可以基于字典(词库)和规则分词。借助词库并采用最长匹配规则，来对文本进行分词。所谓最长匹配，也就是匹配尽可能长的词语。
     - 具体到实现层面，可以将词库中的单词，构建成 Trie 树结构，然后拿网页文本在 Trie 树中匹配。
   - 每个网页的文本信息在分词完成之后，都得到一组单词列表。把单词与网页之间的对应关系，写入到一个临时索引文件中(tmp_Index.bin)，这个临时索引文件用来构建倒排索引文件。
   - 在临时索引文件中，我们存储的是单词编号而非单词本身。这样做的目的主要是为了节省存储的空间
   - 给单词编号的方式，跟给网页编号类似。还需要使用散列表，记录已经编过号的单词。在对网页文本信息分词的过程中，我们拿分割出来的单词，先到散列表中查找，如果找到，那就直接使用已有的编号；如果没有找到，再去计数器中拿号码，并且将这个新单词以及编号添加到散列表中
   - 当所有的网页处理(分词及写入临时索引)完成之后，再将这个单词跟编号之间的对应关系，写入到单词编号文件中，并命名为 term_id.bin。

```
// 临时索引文件格式类似于：
单词编号 \t 网页编号 \r\n
// 单词编号文件格式类似于：
单词编号 \t 单词内容 \r\n
```

## 索引

索引主要负责通过分析阶段得到的临时索引构建倒排索引(Inverted index)，其记录了每个单词以及包含它的网页列表。

在临时索引文件中，记录的是单词跟每个包含它的文档之间的对应关系。那如何通过临时索引文件，构建出倒排索引文件呢？解决这个问题的方法有很多。考虑到临时索引文件很大，无法一次性加载到内存中，搜索引擎一般会选择使用**多路归并排序**的方法来实现。

1. 先对临时索引文件，按照单词编号的大小进行排序。
   - 因为临时索引很大，所以一般基于内存的排序算法就没法处理这个问题了。
   - 可以用之前讲到的归并排序的处理思想，将其分割成多个小文件，先对每个小文件独立排序，最后再合并在一起
2. 临时索引文件排序完成之后，相同的单词就被排列到了一起
3. 只需要顺序地遍历排好序的临时索引文件，就能将每个单词对应的网页编号列表找出来，然后把它们存储在倒排索引文件(index.bin)中
4. 还需要一个 term_offset.bin 文件，来记录每个单词编号在倒排索引文件中的偏移位置。其作用是，帮助快速查找某个单词编号在倒排索引中的位置，进而快速从倒排索引中读取单词编号对应的网页编号列表

```
// 倒排索引文件格式类似于：
单词编号 \t 包含单词的网页编号列表(每个网页之间使用其他分隔符分隔) \r\n
// 单词偏移量文件格式类似于：
单词编号 \t 偏移量 \r\n
```

## 查询

查询主要负责响应用户请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。用之前产生的几个文件，来实现最终的用户搜索功能。

- doc_id.bin：记录网页链接和编号之间的对应关系
- term_id.bin：记录单词和编号之间的对应关系
- index.bin：倒排索引文件，记录每个单词编号以及对应包含它的网页编号列表
- term_offsert.bin：记录每个单词编号在倒排索引文件中的偏移位置。
  四个文件除了倒排索引文件(index.bin)比较大之外，其他的都比较小。为了方便快速查找数据，我们将其他三个文件都加载到内存中，并且组织成散列表这种数据结构。

1. 用户在搜索框中，输入某个查询文本的时候，先对用户输入的文本进行分词处理。假设分词之后，得到 k 个单词；
2. 拿这 k 个单词，去 term_id.bin 对应的散列表中，查找对应的单词编号，会得到了这 k 个单词对应的单词编号；
3. 拿这 k 个单词编号，去 term_offset.bin 对应的散列表中，查找每个单词编号在倒排索引文件中的偏移位置，得到 k 个偏移位置；
4. 拿这 k 个偏移位置，去倒排索引(index.bin)中，查找 k 个单词对应的包含它的网页编号列表，得到了 k 个网页编号列表；
5. 针对这 k 个网页编号列表，统计每个网页编号出现的次数按照出现次数的多少，从小到大排序。出现次数越多，说明包含越多的用户查询单词（用户输入的搜索文本，经过分词之后的单词）。
   - 具体到实现层面，可以借助散列表来进行统计。
6. 得到了一组排好序的网页编号。拿着网页编号，去 doc_id.bin 文件中查找对应的网页链接，分页显示给用户就可以了。

这个简单的搜索引擎只是基本原理，并未涉及计算网页权重的 PageRank 算法、计算查询结果排名的 tf-idf 模型等，涉及的数据结构和算法有：图、散列表、Trie 树、布隆过滤器、单模式字符串匹配算法、AC 自动机、广度优先遍历、归并排序等。

# Disruptor

内存消息队列 Disruptor 是线程间用于消息传递的队列，广泛应用于 Apache Storm、Camel、Log4j2 等。

Disruptor 的底层是基于循环队列的“生产者-消费者模型”。

在多个生产者或多个消费者并发操作队列的情况下，通常会出现以下两个问题：

1. 多个生产者写入的数据可能会互相覆盖；
2. 多个消费者可能会读取重复的数据。

常见的解决这类问题的方法是加锁，将部分代码的执行由并行改为串行，但是这样一来，执行效率也会下降。继续优化的话，可以使用 CAS 操作来减少加锁的粒度。那么，Disruptor 是如何克服这两个问题的呢？

- 生产者

往队列中添加数据之前，先加锁申请可用空闲存储单元，并且是批量地申请连续的 n (n≥1)个存储单元。当申请到这组连续的存储单元之后，后续往队列中添加元素，就可以不用加锁了，因为这组存储单元是这个线程独享的。

- 消费者

处理的过程跟生产者是类似的。先加锁申请一批连续可读的存储单元，当申请到这批存储单元之后，后续的读取操作就可以不用加锁了。

需要注意的是：如果生产者 A 申请到了一组连续的存储单元，假设是下标为 3 到 6 的存储单元，生产者 B 紧跟着申请到了下标是 7 到 9 的存储单元，那在 3 到 6 没有完全写入数据之前，7 到 9 的数据是无法读取的。这个也是 Disruptor 实现思路的一个弊端。

# 鉴权&限流

## 鉴权

实现接口鉴权功能，需要事先将应用对接口的访问权限规则设置好。当某个应用访问其中一个接口的时候，拿应用的请求 URL，在规则中进行匹配。如果匹配成功，就说明允许访问；如果没有可以匹配的规则，那就说明这个应用没有这个接口的访问权限，就拒绝服务。

那么，存储规则的数据结构是什么样的呢？用户请求 URL 在规则中快速匹配，又该用什么样的算法呢？

不同的应用对应不同的规则集合，可以采用散列表来存储这种对应关系。这里主要是每个应用对应的规则集合该如何存储和匹配。

- 精确匹配规则
  - 只有当请求 URL 跟规则中配置的某个接口精确匹配时，这个请求才会被接受、处理

将每个应用对应的权限规则，存储在一个字符串数组中。当用户请求到来时，拿用户的请求 URL，在这个字符串数组中逐一匹配，匹配的算法就是字符串匹配算法(如 KMP、BM、BF 等)。

由于规则不会经常变动，为了加快匹配速度，可以按照字符串的大小给规则排序，把它组织成有序数组这种数据结构。当要查找某个 URL 能否匹配其中某条规则的时候，可以采用二分查找算法，在有序数组中进行匹配。

二分查找算法的时间复杂度是 $O(logn)$（n 表示规则的个数），这比 $O(n)$ 的顺序遍历快了很多。对于规则中接口长度比较长，且鉴权功能调用量非常大的情况，这种优化方法带来的性能提升还是非常可观的。

- 前缀匹配规则
  - 只要某条规则可以匹配请求 URL 的前缀，就说这条规则能够跟这个请求 URL 匹配

可以将每个用户的规则集合，组织成 Trie 树这种数据结构。

不过，Trie 树中的每个节点不是存储单个字符，而是存储接口被“/”分割之后的子目录(以 HTTP 接口“/user/name”为例，被分割为“user”“name”两个子目录)。

由于规则不会经常变动，所以，在 Trie 树中，可以把每个节点的子节点们，组织成有序数组这种数据结构。在匹配的过程中，可以利用二分查找算法，决定从一个节点应该跳到哪一个子节点。

- 模糊匹配规则
  - 规则中包含通配符，比如“\*\*”表示匹配任意多个子目录，“\*”表示匹配任意一个子目录。只要用户请求 URL 可以跟某条规则模糊匹配，就说这条规则适用于这个请求。

采用回溯算法，拿请求 URL 跟每条规则逐一进行模糊匹配。不过，这个解决思路的时间复杂度是非常高的。需要拿每一个规则，跟请求 URL 匹配一遍。如何优化呢？

实际上，并不是每条规则都包含通配符，包含通配符的只是少数。可以把不包含通配符的规则和包含通配符的规则分开处理。

把不包含通配符的规则，组织成有序数组或者 Trie 树(具体组织成什么结构，视具体的需求而定，是精确匹配，就组织成有序数组，是前缀匹配，就组织成 Trie 树)，而这一部分匹配就会非常高效。

剩下的是少数包含通配符的规则，把它们简单存储在一个数组中就可以了。尽管匹配起来会比较慢，但是毕竟这种规则比较少，所以这种方法也是可以接受的。

当接收到一个请求 URL 之后，可以先在不包含通配符的有序数组或者 Trie 树中查找。如果能够匹配，就不需要继续在通配符规则中匹配了；如果不能匹配，就继续在通配符规则中查找匹配。

## 限流

限流，就是对接口调用的频率进行限制。比如每秒钟不能超过 100 次调用，超过之后，我们就拒绝服务。

按照不同的限流粒度，限流可以分为很多种类型。比如给每个接口限制不同的访问频率，或者给所有接口限制总的访问频率，又或者更细粒度地限制某个应用对某个接口的访问频率等等。

不同粒度的限流功能的实现思路都差不多，这里主要针对限制所有接口总的访问频率这样一个限流需求。如何实现精准限流？

- 固定时间窗口限流算法

最简单的限流算法就是**固定时间窗口限流算法**。

选定一个时间起点，之后每当有接口请求到来，就将计数器加一。如果在当前时间窗口内，根据限流规则(如每秒钟最大允许 100 次访问请求)，出现累加访问次数超过限流值的情况时，我们就拒绝后续的访问请求。当进入下一个时间窗口之后，计数器就清零重新计数。

这种基于固定时间窗口的限流算法的缺点是，限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。

假设每秒不能超过 100 次接口请求，而第一个 1s 的时间窗口中，100 次请求都集中在最后 10ms 内，而第二个 1s 的时间窗口中，100 次请求都集中在开始的 10ms 内，尽管两个时间窗口都符合限流要求，但在两个时间窗口临界的 20ms 内，会集中有 200 次接口请求。固定时间窗口限流算法并不能对这种情况做限制，所以，集中在这 20ms 内的 200 次请求就有可能压垮系统。

- 滑动时间窗口限流算法

对固定时间窗口限流算法改进：**滑动时间窗口限流算法**。限制任意时间窗口(如 1s)内，接口请求数都不能超过某个阈值(如 100 次)。流量经过滑动时间窗口限流算法整形之后，可以保证任意一个 1s 的时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑。具体如何实现呢？

假设限流的规则是，在任意 1s 内，接口的请求次数都不能大于 K 次。我们就维护一个大小为 K+1 的循环队列，用来记录 1s 内到来的请求。注意，这里循环队列的大小等于限流次数加一，因为循环队列存储数据时会浪费一个存储单元。

当有新的请求到来时，我们将与这个新请求的时间间隔超过 1s 的请求，从队列中删除。然后再来看循环队列中是否有空闲位置。如果有，则把新请求存储在队列尾部(tail 指针所指的位置)；如果没有，则说明这 1 秒内的请求次数已经超过了限流值 K，所以这个请求被拒绝服务。

基于时间窗口的限流算法，不管是固定时间窗口还是滑动时间窗口，只能在选定的时间粒度上限流，对选定时间粒度内的更加细粒度的访问频率不做限制。

针对这个问题，还有很多更加平滑的限流算法，比如令牌桶算法、漏桶算法等。

额外内容：[微服务接口限流的设计与思考](https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488993&idx=1&sn=4b9d5deedd0e626c456744f04b499bbb&=41#wechat_redirect)
