# 堆

堆是一种特殊的树：

- 堆必须是一个完全二叉树；
  - 之前说过，完全二叉树适合使用数组存储，会很省内存，所以堆适合用数组存储
- 堆中每一个节点的值都必须大于等于(或小于等于)其子树中每个节点的值
  - 所以堆中只有堆顶元素是最有用的，因为堆顶元素即为堆中的最大(或最小)值

尽管二叉堆也维持着相对的顺序，但二叉堆的条件相对宽松，只要求父节点大(小)于子节点。

向堆中插入数据，并进行调整使其重新满足堆的特性，这一过程叫做**堆化(heapify)**。

堆化有两种：siftUp(上浮)、siftDown(下沉)。分别为节点沿着路径向上或向下比较值的大小，然后交换。而堆化是顺着节点所在路径进行比较和交换的，所以堆化的时间复杂度与树的高度成正比，即 $O(logn)$。

以下如不特殊说明均以最大堆(即节点的值大于等于其子树中每个节点的值)为例！

```go
type MaxHeap struct {
	size int // 堆中元素的数量
	data []int
}

func NewHeap() *MaxHeap {
	heap := &MaxHeap{size: 0, data: make([]int, 0)}
	return heap
}
// 查找 index 索引对应节点的父节点
func (heap *MaxHeap) parent(index int) int {
	if index == 0 {
		panic("index 0 does not have parent")
	}
	return (index - 1) / 2
}
// 查找 index 索引对应节点的左子节点
func (heap *MaxHeap) leftChild(index int) int {
	return 2*index + 1
}
// 查找 index 索引对应节点的右子节点
func (heap *MaxHeap) rightChild(index int) int {
	return 2*index + 2
}
// 交换堆中索引为 i、j 对应节点的值
func (heap *MaxHeap) swap(i, j int) {
	if i < 0 || i >= heap.size || j < 0 || j >= heap.size {
		panic("index is illegal")
	}
	heap.data[i], heap.data[j] = heap.data[j], heap.data[i]
}
```

## 插入操作

每次向数组末尾插入数据，然后让新的节点与其父节点对比，如果新节点大，则交换两个节点的值，然后继续向上比较，直到父子节点满足父节点的值 > 子节点的值。由于这一过程是新节点逐渐上向上移动，所以为 siftUp。

插入操作的主要逻辑就是堆化，故时间复杂度也为 $O(logn)$。

```go
// 对索引为 index 的节点进行上浮操作
func (heap *MaxHeap) siftUp(index int) {
	// index>0 说明该节点的父节点存在，且 index 所对应节点的值比其父节点的值大就进行上浮
	for index > 0 && heap.data[index] > heap.data[heap.parent(index)] {
		// 交换 index 和 indexP 的值
		heap.swap(index, heap.parent(index))
		// 更新 index 和 indexP 的值
		index = heap.parent(index)
	}
}

func (heap *MaxHeap) Insert(data int) {
	heap.data = append(heap.data, data)
	heap.size++
	heap.siftUp(heap.size - 1)
}
```

## 移除堆顶元素

最大堆的根节点为堆中的最大值，当移除了堆顶的元素后，就需要把左右子节点的最大值放到堆顶，然后重复这个操作，直到叶子节点被删除。但是这一过程最后得到的可能并不是完全二叉树(可画图理解)。所以需要换一种方式来移除堆顶元素。

可以先交换堆顶元素(数组索引为 0)和最后一个叶子节点(数组最后一个元素)，删除此时的最后一个叶子节点(即原堆顶元素)，然后将此时的堆顶元素与其左右子节点对比，如果堆顶元素最小，就和最大的子节点交换，然后重复这一对比交换操作，最后得到的就是一个完全二叉树，而堆顶元素逐渐下移的过程即为 siftDown。

移除堆顶元素的主要逻辑就是堆化，故时间复杂度也为 $O(logn)$。

```go
// 对索引为 index 的节点进行下沉操作
func (heap *MaxHeap) siftDown(index int) {
	// index 存在左节点
	for heap.leftChild(index) < heap.size {
		// max 用于保存 index 两个子节点中的最大值的索引
		max := heap.leftChild(index)
		// index 存在右子节点，且右子节点的值 > 左子节点的值
		if max+1 < heap.size && heap.data[max+1] > heap.data[max] {
			max = heap.rightChild(index)
		}
		// 如果 index 的值比其两个子节点的值都大，停止下沉
		if heap.data[index] >= heap.data[max] {
			break
		}
		// 将子节点的最大值与 index 的值交换
		heap.swap(index, max)
		// 更新 index，便于继续下沉
		index = max
	}
}

func (heap *MaxHeap) RemoveMax() int {
	if heap.size == 0 {
		panic("can't find max when heap is empty")
	}
	max := heap.data[0]
	heap.swap(0, heap.size-1)
	heap.data = heap.data[:heap.size-1]
	heap.size--
	heap.siftDown(0)
	return max
}
```

# 堆排序

堆排序主要有两步：数组堆化、排序。

## heapify

将任意数组整理成堆的形状：

叶子节点不需要进行 siftDown 操作，因为其已经处于最下层了，所以只需要将非叶子节点进行 siftDown 操作，而从后往前第一个非叶子节点为数组最后一个元素的父节点。

```go
func Heapify(arr []int) *MaxHeap {
	if len(arr) > 1 {
		heap := &MaxHeap{size: len(arr), data: arr}
		for i := heap.parent(len(arr) - 1); i >= 0; i-- {
			heap.siftDown(i)
		}
	}
	heap := &MaxHeap{size: len(arr), data: arr}
	return heap
}
```

siftDown 的节点从倒数第二层开始，每个节点在 siftDown 的过程中需要比较和交换的节点个数，与该节点的高度 k 成正比，只要将每个节点的高度求和，就可以得到建堆的时间复杂度：

$$
高度 h：  节点个数为 2^0 = 1 \\
高度 h-1：节点个数为 2^1 = 2 \\
高度 h-2：节点个数为 2^2 = 4 \\
	... \\
高度 k：	节点个数为 2^k \\
	... \\
高度 1：  节点个数为 2^{h-1} \\
总的高度 S = 1*h + 2^1*(h-1) + 2^2*(h-2)+...2^k*(h-k)+...2^{h-1}*1 \\
等差数列*等比数列，采用错位相减法得到：\\
S = 2^{h+1}-h-2 \\
又  h=log_2n \\
所以时间复杂度 = O(n)
$$

## 排序

堆数组进行堆化后，数组中的第一个元素(堆顶元素)即为最大值。

1. 将堆顶元素与最后一个元素交换，该过程类似移除堆顶元素；
2. 对剩下的元素进行堆化(这里是 siftDown)使其重新成为堆；
3. 将堆顶元素与倒数第二个元素交换；
4. 重复上述步骤，直到最后堆中只剩下标为 1 的一个元素，最终得到的就是一个从小到大排序的数组。

```go
func HeapSort(arr []int){
	heap := Heapify(arr)
	k := len(arr) - 1
	for k > 0 {
		heap.swap(0, k)
		heap = Heapify(arr[:k])
		k--
	}
}
```

## 分析

- 堆排序是原地排序算法；
- 堆排序包括堆化和排序两个操作
  - 堆化的时间复杂度为 $O(n)$，排序的时间复杂度为 $O(nlogn)$，所以堆排序的时间复杂度为 $O(nlogn)$
- 堆排序并不是稳定的排序算法，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序

对比堆排序和快排：

- 堆排序数据访问的方式没有快速排序友好
  - 快排中数据是顺序访问的，而堆排序中数据是跳着访问的，对 CPU 缓存不友好
- 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序
  - 对数组堆化的过程会打乱数据原有的相对先后顺序，导致有序度降低，数据更无序了

# 堆的应用

## 优先队列

普通队列是 LILO，而优先队列的出队顺序与入队顺序无关，和优先级相关，优先级最高的，最先出队。

使用堆实现优先队列是最高效的，因为堆和优先队列很相似，堆顶元素即为优先级最高的元素。

Java 的 `PriorityQueue`，C++ 的 `priority_queue` 都是优先队列的实现。

### Go 实现

使用 `container/heap` 中的 heap 实现一个优先队列(参考了该包下的 example_pq_test.go 文件)

```go
type Vertex struct {  // 优先队列中的元素类型
	id   int // 顶点编号
	dist int // 起始顶点到该顶点的距离
}
// 该类型需要实现 heap.Interface 接口(该接口还包含了 sort.Interface 接口)
type PriorityQueue []*Vertex
// 返回队列中元素个数，该方法属于 sort.Interface 接口
func (p PriorityQueue) Len() int {
	return len(p)
}
// 比较队列中索引为 i、j 两个元素的大小，该方法属于 sort.Interface 接口
// 这里是距离越小优先级越高，生成一个最小堆，反之得到一个最大堆
func (p PriorityQueue) Less(i, j int) bool {
	return p[i].dist < p[j].dist
}
// 交换队列中索引为 i、j 两个元素的大小，该方法属于 sort.Interface 接口
func (p PriorityQueue) Swap(i, j int) {
	p[i], p[j] = p[j], p[i]
	p[i].id = i
	p[j].id = j
}
// 向队列中添加一个元素，该方法属于 heap.Interface 接口，不允许直接调用需要通过 heap.Push() 间接调用
func (p *PriorityQueue) Push(x interface{}) {
	n := len(*p)
	vertex := x.(*Vertex)
	vertex.id = n
	*p = append(*p, vertex)
}
// 移除堆顶元素，该方法属于 heap.Interface 接口，不允许直接调用需要通过 heap.Pop() 间接调用
func (p *PriorityQueue) Pop() interface{} {
	old := *p
	n := len(old)
	item := old[n-1]
	old[n-1] = nil  // avoid memory leak
	item.id = -1  // for safety
	*p = old[0 : n-1]
	return item
}
```

在 example_pq_test.go 文件中还有一个函数可以更新优先级，这里没有列出。使用：

```go
func TestPriorityQueue(t *testing.T) {
	pq := make(PriorityQueue, 6)
	pq[0] = &Vertex{0, 77}
	pq[1] = &Vertex{1, 100}
	pq[2] = &Vertex{2, 120}
	pq[3] = &Vertex{4, 10}
	pq[4] = &Vertex{5, 75}
	pq[5] = &Vertex{3, 99}
	heap.Init(&pq)  // 借助 heap.Init() 对其堆化
	v := &Vertex{5, 101}
	heap.Push(&pq, v)  // 通过 heap.Push() 添加元素
	for _, v := range pq {
		t.Log(v)
	}
	for pq.Len() > 0 {
		v := heap.Pop(&pq).(*Vertex)  // 通过 heap.Pop() 弹出堆顶元素
		t.Logf("%+v", v)
	}
}
```

### 优先队列用途

那么优先队列又有哪些实际的用途呢？

- 合并有序小文件

Q：假设有 100 个小文件，每个文件 100MB，文件中存储的都是有序的字符串，如何将这些 100 个小文件合并成一个有序的大文件？

A：整体思路类似于归并排序的归并

如果使用数组实现，每次从 100 个文件中取出第一个字符串放入数组，然后比较数组中所有元素，将最小的字符串(假设来自 33.txt)写入合并后的文件，并将其从数组中删除，再从 33.txt 取出下一个字符串，重复上面的比较、写入、删除操作，直到所有数据都写入到大文件中。由于每次取最小值都需要遍历整个数组，这很低效。

而如果使用优先队列(即堆)，将从小文件中取出的字符串放入最小堆中，则堆顶元素即为最小字符串，把这个字符串写入大文件，并将其从队中删除，然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。由于删除堆顶数据和往堆中插入数据的时间复杂度都是 $O(logn)$，n 为堆中数据的个数即 100。

- 高性能定时器

定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间(如 1 秒)，就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。

但是这样的做法很低效，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。

如果使用优先队列，可以按照任务设定的执行时间，将任务存储到优先队列中，队列首部(最小堆堆顶)为存储最先执行的任务。这样，定时器就不需要每隔 1 秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。定时器就可以设定在 T 秒之后，再来执行任务。从当前时间点到(T-1)秒这段时间里，定时器都不需要做任何事情。当 T 秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。

定时器既不用间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。

## Top K

有两类 Top K 问题：

- 针对静态数据集合：一个包含 n 个数据的数组中，查找前 K 大数据

先用前 K 的元素生成一个大小为 K 的最小堆，遍历后续数组中的而元素，从数组中取出数据与堆顶元素比较。如果比堆顶元素大就把堆顶元素删除，并将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了。

遍历数组需要 $O(n)$ 的时间复杂度，一次堆化操作需要 $O(logK)$ 的时间复杂度，所以最坏情况下，n 个元素都入堆一次，时间复杂度就是 $O(nlogK)$。

- 针对动态数据集合：即实时 Top K

和上面类似，先用前 K 次添加的数据生成一个大小为 K 的堆，当再有数据被添加时，和堆顶元素对比，如果比堆顶元素大，就把堆顶元素删除，并将这个元素入堆；否则不做处理。这样，无论任何时候需要查询当前的前 K 大数据，都可以立刻返回给他。时间复杂度为 $O(nlogK)$。

Q：假设有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到 Top 10 最热门的搜索关键词？

A：

1. 首先要统计每个搜索关键词出现的频率
   - 可通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数
2. 建立一个大小为 10 的最小堆，遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。
   - 如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中
3. 遍历结束后，堆中数据即为 Top 10 的搜索关键词

上述方法存在漏洞：假设 10 亿条搜索关键词中不重复的有 1 亿条，如果每个搜索关键词的平均长度是 50 个字节，那存储 1 亿个关键词起码需要 5GB 的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了。而我们的机器只有 1GB 的可用内存空间，所以我们无法一次性将所有的搜索关键词加入到内存中。

1. 可以先使用哈希算法对数据分片，分到 10 个或更多文件中，
   - 此时每个文件中关键词的数量就少了很多，去除重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB，1GB 内存足够了。
2. 针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10
3. 把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词，即 10 亿数据中的 Top 10 最频繁的搜索关键词了。

## 求中位数

如果数据量为奇数，返回中间位置的数据，如果数据量为偶数，返回中间两个元素的前一个(也可以是后一个)。

如果是静态数据，中位数是固定的，可以先排序，每次查询时返回这个固定值即可，尽管排序的代价较大，但边际成本低。

如果是动态数据，中位数一直变动，此时再采用先排序的方法，效率就很差了。可以借助堆来实现，

维护两个堆，一个最大堆、一个最小堆，最大堆存储较小的一半数据，最小堆存储较大的一半数据，即最小堆中的数据均大于最大堆中的数据。假设有 n 个数据，n 为偶数时，最大堆存储前(假设排序后) n/2 个数据，最小堆存储后 n/2 个数据，最大堆的堆顶元素即为虽求中位数；n 为奇数时，最大堆存储前 n/2 + 1 个数据，最小堆存储后 n/2 个数据，最大堆的堆顶元素仍是中位数。

添加数据时，如果数据大于最大堆的堆顶元素，就将其插入最小堆，否则放入最大堆。为了维护两个堆的数量，使其仍满足之前所说的情况，可以从一个堆中不停地将堆顶元素移动到另一个堆中。

插入操作涉及到堆化，时间复杂度为 $O(nlogn)$，但是求中位数只需要返回最大堆的堆顶元素，复杂度为 $O(1)$。

中位数是数据排序后位于 50% 位置的元素，类似的，堆还可以求其他百分位的元素，只要合理控制两个堆中的数据量即可。如：最大堆保存 99% 的数据，最小堆存 1% 的数据。
