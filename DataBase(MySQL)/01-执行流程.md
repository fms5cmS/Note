# 1.连接器

- 连接到数据库上。连接器负责与客户端建立连接、获取权限、维持和管理连接

```shell
# mysql 是客户端工具，用于跟服务端建立连接
# $xx代表输入的参数
mysql -h$IP -P$port -u$user -p
```

用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。

注：该用户建立连接后，即使使用管理员证号修改了该用户权限，也不会影响已存在连接的权限。重新建立连接后才会使用新的权限设置。

数据库中的长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接；短连接指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个连接使用。

建立连接的过程通常是比较复杂的，所以建议尽量使用长连接。

而如果**全部使用长连接，有时 MySQL 占用内存会涨的很快**。因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。

如何解决上述问题呢？两个方案：

- **定期断开长连接**。使用一段时间，或程序中判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连
- 如果使用的是 MySQL 5.7及之后版本，可以在每次执行一个比较大的操作后，通过执行 `mysql_reset_connection` 来**重新初始化连接资源**。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

# 2.查询缓存

MySQL 收到查询请求后，会先到查询缓存中查找是否执行过这条语句。

查询缓存通常弊大于利，因为查询缓存的失效非常频繁，只要对一个表进行更新，该表上所有的查询缓存都会被清空。

MySQL 8.0 开始，抛弃了查询缓存这个功能。

# 3.分析器

分析器对 SQL 语句做解析。依次完成词法分析、语法分析。

注意：分析器会对 SQL 语句中的表、字段是否存在做判断。

# 4.优化器

经过分析器后，MySQL 就知道你要做什么了。开始执行前，还需要经过优化器处理。

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

# 5.执行器

开始执行前，先判断一下用户对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误；如果有权限，就打开表继续执行。

打开表时，执行器会根据表的引擎定义，去使用这个引擎提供的接口。示例：

```sql
select * from T where ID=10;
```

1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 是不是 10。不是则跳过，是则将这条记录存在结果集中
2. 调用引擎接口取下一行，重复相同的判断逻辑，直到取到该表的最后一行；
3. 执行器将上述遍历过程中所有满足条件的结果集返回给客户端

对于有索引的表，执行逻辑也差不多。

数据库的慢查询日志中 `rows_examined` 字段就是 SQL 语句执行过程中扫描了多少行。这个值时执行器每次调用引擎获取数据行时累加的。

有些场景下，执行器调用一次，在引擎内部会扫描多行，所以引擎扫描行数与 `rows_examined`  并不完全相同。

# 日志系统

与查询语句的执行流程（连接器 -> 分析器 -> 优化器 -> 执行器 -> 存储引擎）类似，更新语句也会同样走一遍相同的流程，而更新语句会把相关表的所有缓存结果清空，更重要的是，更新流程还涉及两个重要的日志模块：

- binlog（归档日志）
  - MySQL Server 层实现的，所有引擎都可以使用
  - 逻辑日志，记录了语句的原始逻辑，如“给 id=2 这一行数据的 c 字段加 1”
    - 有两种格式，statement 模式记录 SQL 语句，row 模式记录行的内容（记录更新前、后两条记录）
  - 可以追加写入，写到一定大小后切换写一个 binlog 文件，不会覆盖以前的日志

- redo log（重做日志）
  - InnoDB 引擎特有的
  - 物理日志，记录了“在某个数据页做了什么修改”
  - 循环写的，空间固定会用完



## redo log（重做日志）

MySQL 没有 InnoDB 引擎之前，其自带引擎为 MyISAM，并不具备 crash-safe 的能力。而 InnoDB 引擎通过 redo log  就可以实现 crash-safe 的能力，保证即使数据库发生异常重启，之前提交的记录都不会丢失。

MySQL 中常说的 WAL（Write-Ahead Logging）技术，其关键点在于先写日志，再写磁盘。

**当有一条记录需要更新时，InnoDB 引擎会把记录写到 redo log 中，并更新内存，这时更新就算完成了。同时 InnoDB 会在适当（系统比较空闲）的时候将这个操作记录更新到磁盘中。**

InnoDB 的 redo log 是固定大小的。记录时是循环写入的，从头开始写，写到末尾又回到开头循环写。

- write pos 是当前记录的位置，一边写一边后移，写到末尾后又会回到开头
- checkpoint 是当前要擦除的位置，擦除记录前要把记录更新到数据文件

write pos 和 checkpoint 之间是空闲位置，可用于记录新的操作，如果 write pos 追上 checkpoint 就表示 redo log 满了，此时不能再执行新的更新，需要停下来先擦掉一些记录，把 checkpoint 推进一下。

redo log 会定期刷盘，不一定等到满了才刷盘。

`innodb_flush_log_at_trx_commit` 设置为 1 时，表示每次事务的 redo log 都直接持久化到磁盘。建议设置，保证 MySQL 异常重启后数据不丢失。

`sync_binlog`设置为 1 时，表示每次事务的 binlog 都持久化到磁盘。建议设置，保证 MySQL 异常重启后 binlog 不丢失。



## 更新流程

举例说明 InnoDB 引擎执行 update 语句时的内部流程：

```sql
update T set c=c+1 where id=2;
```

1. 执行器找到引擎取 id=2 这一行。id 是主键，引擎会使用树搜索找到这一行
   1. 如果这一行所在数据页在内存中，直接返回给执行器
   2. 否则，先从磁盘读入内存再返回
2. 执行器拿到数据后，把这个值加 1，得到新的一行数据，调用引擎接口写入这行新数据
3. 引擎将这行新数据更新到内存，同时把更新操作记录到 redo log 中，此时 redolog 处于 prepare 状态，然后告知执行器执行完成，随时可以提交事务
4. 执行器生成该操作的 binlog，并写入磁盘
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改为 commit 状态，更新完成。



## redo log的两阶段提交

**数据恢复**：binlog 采用追加写的形式记录所有逻辑操作。如果某天有一次误删表，需要找回数据，可以先找到最近的一次全量备份，然后从备份的时间点开始，将备份的 binlog 取出来，重放到误删表前的时刻。

上面的更新流程中，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。

利用反证法，**redo log 和 binlog 是两个独立逻辑**，如果不使用两阶段提交，在 redo log 和 binlog 之间发生异常重启时，恢复的数据会有问题！

注：更新操作中，InnoDB 引擎把记录写到 redo log 中，并更新内存就算是更新完成了。刷盘是在系统空闲时才进行的。

- 先写 redo log 后写 binlog

由于 redo log 已成功写入，所以原库中更新已完成，但是 binlog 未写入，所以利用 binlog 恢复的是更新前的数据，会丢失数据

- 先写 binlog 后写 redo log

由于 redo log 未成功写入，所以原库中更新操作执行失败，但是 binlog 已完成写入，所以利用 binlog 恢复的数据多了相关的更新操作

