[消息队列](../Architecture/03-消息队列.md)

两个常见的消息服务规范：JMS(Java Message Service)；AMQP（Advanced Message Queuing Protocol）

# 消息模型

- 队列模型

消息的顺序就是生产者发送的顺序，任何一条消息只能被一个消费者消费，所以同一个队列的多个消费者是竞争关系。

- 发布-订阅模型（Publish-Subscribe Pattern）

在队列模型中，如果一个消息分发给多个消费者，要求每个消费者都收到全量消息，单个队列就无法满足，需要为每个消费者创建一个单独的队列，且生产者发送多份消息。

为了解决该问题，演化出了另一种消息模型：发布-订阅模型。Publisher 将消息发送到 Topic 中，Subscriber 在接受消息之前需要先 Subscribe Topic。

> Publisher 消息的发送方
> Subscriber 消息的接受方
> Topic 服务端存放消息的容器

两个模型最大的区别就是：一份消息能不能被消费多次！

实际上，如果只有一个 Subscriber，那么发布-订阅模型和队列模型基本就是一样的了，也就是说，发布-订阅模型在功能层面上可以兼容队列模型。

现代的 MQ 使用的消息模型大多是发布-订阅模型。也存在部分例外，如 RabbitMQ。

RabbitMQ 的消息模型依然是队列模型。在生产者和队列中间有一个 Exchange 模块，生产者将消息统一发送给 Exchange，然后由 Exchange 上配置的策略决定将消息投递到哪些队列中。同一份消息如果需要被多个消费者消息，需要配置 Exchange 将消息发送到多个队列，每个队列都存放一份完整的该消息数据。

RocketMQ 的消息模型是标准的发布-订阅模型，RocketMQ 中依然由 Queue 队列的概念。

为了防止消息投递过程中忧郁网络或服务器故障丢失，几乎所有 MQ 都采用了 **“请求-确认” 机制**，见下面“消息丢失-确保消息可靠传递”部分。

这个机制保证了消息传递过程中的可靠性，但是存在问题。为了保证消息的有序性，在某一条消息被成功消费之前，下一条消息是无法被消费的，否则违背了有序性的原则。

为了解决这个问题，RocketMQ 在 Topic 下面增加了 Queue 的概念！每个 Topic 包含多个 Queue，通过多个 Queue 来实现多实例并行生产和消费。RocketMQ 仅在队列上保证消息的有序性，Topic 层面上无法保证严格的顺序。

RocketMQ 中，Subscriber 的概念是通过消费者组 Consumer Group 来体现的。每个消费者组都消费 Topic 中一份完整的消息，不同的消费者组之间消费进度彼此不受影响。也就是说，一条消息被消费者组A 消费过，也会再给消费者组B 消费。

消费者组中包含多个消费者，同一个组内的消费者是竞争关系，如果一条消息被 Consumer1 消费了，那么同组的 Consumer2 就不会再收到这条消息。

在 Topic 的消费过程中，由于消息需要被不同组进行多次消费，所以消费完的消息不回被立即删除，所以需要 RocketMQ **为每个消费者组在每个队列上维护一个消费位置 Consumer Offset**，每成功消费一条消息，值加一，这个位置之前的消息都被消费过，之后的消息都没有被消费过。

由于消费者是不记录消费位置的，它消费的时候只管去找 Broker 要消息，Broker 必须知道消费到哪儿了，好找出下一条或下一批消息给客户端。

Kafka 的消息模型和 RocketMQ 是完全一样的，唯一的区别是，队列这个概念在 Kafka 中对应的是分区 Partition！含义和功能没有任何区别。

对于一个消费组，每个队列上只能串行消费，多个队列加一起就是并行消费了，并行度就是队列数量，队列数量越多并行度越大，所以水平扩展可以提升消费性能。

# 事务消息

事务消息需要 MQ 提供功能才能实现，Kafka、RocketMQ 都提供了事务相关的功能，都是基于两阶段提交实现的。

不同之处在于对处于事务中的消息的处理方式，RocketMQ 是把这些消息暂存在一个特殊的队列中，待事务提交后再移动到业务队列中；而 Kafka 直接把消息放到对应的业务分区中，配合客户端过滤来暂时屏蔽进行中的事务消息。

适用场景也是不一样的，RocketMQ 的事务适用于解决本地事务和发消息的数据一致性问题，而 Kafka 的事务则是用于实现它的 Exactly Once 机制，应用于实时计算的场景中。

示例：订单系统创建订单后，发送消息，然后购物车系统收到消息清空购物车。

1. 订单系统在 MQ 上开启一个事务，然后订单系统给消息服务器发送一个"半消息"（包含了完整的消息内容，但在事务提交之前，对于消费者而言，该消息是不可见的）；
2. 半消息发送成功后，订单系统就可以执行本地事务了，创建订单记录并提交订单库的数据库事务，然后根据本地事务的执行结果决定提交或回滚事务消息
   1. 如果订单创建成功，提交事务消息，购物车系统就可以消费到这条消息继续后面的流程
   2. 如果订单创建失败，回滚事务消息，购物车系统就不会收到这条消息了

那么，如果在最后提交事务消息时失败了怎么办？

- Kafka 会直接抛出异常，让用户自行处理； 
- RocketMQ 增加了事务反查机制来解决这个问题，如果 Broker 没有收到提交或回滚的请求，就会定期去 Producer 上反查这个事务对应的本地事务的状态，根据状态来决定提交还是回滚。

> 为了支撑事务反查机制，业务代码需要实现一个反查本地事务状态的接口。如根据消息中的订单 ID 在数据库中查询订单是否存在，存在则返回成功，否则返回失败。

[利用事务消息实现分布式事务](https://github.com/fms5cmS/arts/blob/master/share/04_transaction.md)

# 消息丢失

## 检测消息丢失

可以利用消息队列的有序性来验证是否有消息丢失。

原理：在 Producer 端给发出的每个消息附加一个连续递增的序号，然后在 COnsumer 端检查序号的连续性。

如果监测到序号不连续，那就是丢消息了，还可以通过缺失的序号来确定丢失了哪条消息，方便进一步排查。

多数 MQ 的客户端支持拦截器机制，可以利用该机制，在 Producer 发送消息前的拦截器中将序号注入消息，在 Consumer 收到消息的拦截器中检测序号连续性。这样消息检测的代码不会侵入业务代码中，也方便后续关闭或删除该逻辑。

如果是分布式系统中实现这个检测方法，需要注意：

- Kafka、RocketMQ 时不保证在 Topic 上的严格顺序的，只能保证分区上消息的有序性，所以发消息的时候必须指定分区，且在每个分区单独检测序号连续性
- 如果 Producer 是多实例的，由于不好协调多个 Producer 间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并附上 Producer 的标识，在 Consumer 端按每个 Producer 分别检测序号连续性
- Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。

## 确保消息可靠传递

为了防止消息投递过程中忧郁网络或服务器故障丢失，几乎所有 MQ 都采用了 **“请求-确认” 机制**。

- 生产阶段，生产者先将消息发送给服务端（Broker），Broker 收到消息并将其写入 Topic 或 Queue 中，然后给生产者发送确认的响应。如果生产者未收到 Broker 的确认或收到失败的响应，则重发消息，如果重试再失败，会以返回值或异常的方式通知用户，

> 在写消息发送代码时，注意 正确处理返回值或捕获异常

- 存储阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。可以通过配置 Broker 参数。
  - 单节点，配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费
  - 集群，将 Broker 集群配置成: 至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。

- 消费阶段，消费者收到消息并完成自己的消费业务逻辑后，也会给 Broker 发送消费成功的确认，Broker 只有收到消费确认后，才认为一条消息被成功消费，否则会给消费者重发消息，知道收到对应的消费成功确认。

> 在写消息消费代码时，注意 不要收到消息后就立即发送消费确认，而是在执行完所有消费业务逻辑后在发送消费确认。

这个机制保证了消息传递过程中的可靠性。

# 重复消费

消息重复的情况必然存在！在 MQTT 协议中，给出了三种传递消息时能提供的服务质量标准，服务质量从低到高：
- At most once，至多一次，消息在传递时，最多会被送达一次。没什么消息可靠性保证，允许丢消息。
- Al least once，至少一次，消息在传递时，至少会被送达一次，不允许丢消息，但是允许有少量重复消息出现。
- Exactly once，恰好一次，消息在传递时，只会被送达一次，不允许丢失也不允许重复。

这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。现在常用的绝大部分 MQ 提供的服务质量都是 At least once，很闹保证消息不重复。

一般解决重复消息的方法是，在消费端做消费幂等！

从对系统的影响结果来说，At least once + 消费幂等 = Exactly once。

如果做消费幂等呢？从业务逻辑设计上入手，将消费的业务逻辑设计为具备幂等性的操作。常用的设计幂等操作的方法：

- 利用数据库的唯一约束实现幂等
  - 不仅是关系型数据库，在 Redis 中还可以用 `SETNX` 命令来替代数据库中的唯一约束
- 为更新的数据设置前置条件
  - 如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。
  - 更通用的方法：给数据增加一个版本号属性，每次更新数据前，比较当前数据版本号是否和消息中的版本号一致，更新时需要将版本号加一
- 记录并检查操作，也叫 Token 机制或全剧唯一 ID 机制
  - 思路：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。
  - 在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。
  - 难点：
    - 给每个消息置顶一个全局唯一 ID；
    - “检查消费状态-更新数据-设置消费状态”三个操作必须具备原子性，可以通过事务或加锁实现，但分布式系统中分布式事务和分布式锁都是难题。

> 为什么大部分 MQ 只提供 At least once，而不提供更高质量的 Exactly once？
> MQ 即使做到了 Exactly once，Consumer 还是需要做消费幂等，因为 Consumer 从 Broker 消费消息，如果消费成功，但 Ack 确认的响应发送失败，Consumer 还是会取到重复的消息。
>
> Kafka 在 0.11 版本引入了幂等性 Producer Exactly once，Producer 无论向 Server 发送多少重复数据，Server 端都只持久化一条。
> 开启幂等性的 Producer 在初始化时会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number，而 Broker 会对 <PID, SequenceNumber> 做缓存，当具有相同主键的消息提交时，Broker 仅持久化一条
> 注：PID 重启后会变化，同时不同的 Partition 也具有不同主键，所以该特性无法保证跨分区会话的 Exactly once
> 但是消费端还是需要做幂等

# 消息积压

## 如何避免

优化性能来避免消息积压。

> 在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者的业务逻辑中。对于消息队列本身的性能，作为使用者，不需要太关注。
> 对于绝大多数使用消息队列的业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。主流消息队列的单个节点，消息收发的性能可以达到每秒钟处理几万至几十万条消息的水平，还可以通过水平扩展 Broker 的实例数成倍地提升处理能力。

- 发送端性能优化

发送端业务代码的处理性能，实际上和消息队列的关系不大，因为一般发送端都是先执行自己的业务逻辑，最后再发送消息。

只需要**设置合适的并发和批量大小**就能达到很好的发送性能。

如果发送端是微服务，主要接受 RPC 请求处理在线业务，在处理每次请求时，就在当前线程直接发送消息即可，RPC 框架都是支持并发的，也就实现了并行发送消息。至于是否批量发，取决于业务。

如 Kafka 异步批量的设计，当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，导致在每秒消息数量不多的情况下，Kafka 的时延较高。

如果是离线分析系统，并不关心时延，而注重系统的吞吐量，这种情况更适合批量读取数据然后批量发送消息，少量并发就可以获得高吞吐。

- 消费端性能优化

使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。

所以，设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能。

消费端的性能优化除了**优化消费业务逻辑**以外，也可以通过**水平扩容**，**增加消费端的并发数**来提升总体的消费性能。

注意：在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区(也叫队列)数量，确保 Consumer 的实例数和分区数量是相等的。

如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。因为对于消费者来说，在每个分区上实际上只能支持单线程消费。

一个错误的方案：为了避免消息积压，收到消息后不做任何业务处理，而是把消息放到一个内存队列中就返回，然后它再启动多个业务线程来处理消息的业务逻辑，这些线程从内存队列中取消息处理，从而解决耽搁 Consumer 无法并行消费的问题。

但是，上面这个方案会丢消息！！如果收消息的节点发生宕机，在内存队列中还未处理的消息就会丢失。

## 如何处理

消息积压的原因很多，无法一概而论。粗粒度的原因：消息生产变快；消息消费变慢。

如果是单位时间内发送消息增多，如赶上大促活抢购，短时间不太可能有话消费端逻辑提升消费性能，唯一的方法是扩瞳消费端实例数提升总体消费能力。

> 如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。

如果是消费变慢了，需要检查消费实例，分析原因。优先看日志是否有大量消费错误，还可以通过打印堆栈信息看是不是消费线程出发了死锁活卡在等待某些资源上了。

如果生产和消费速度相比原来没什么变化，需要检查消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。

# 如何保证消息的严格顺序

Topic 层面无法保证严格顺序，只有在队列/分区上才能保证消息的严格顺序

如果要求全局严格顺序，只能把分区数配置为 1，生产者和消费者也只能是一个实例，

如果要保证局部严格顺序，可以这样：在发送端，使用账户 ID 作为 Key，采用一致性哈希算法计算出队列编号，指定队列来发送消息。一致性哈希算法可以保证，相同 Key 的消息总是发送到同一个队列上，这样可以保证相同 Key 的消息是严格有序的。如果不考虑队列扩容，也可以用队列数量取模的简单方法来计算队列编号。

# 为什么使用 MQ

- 解耦，基于发布-订阅机制，可以联动一个或多个业务下游子系统，来保证数据一致性

> 如创建订单后清空购物车的功能对于创建订单业务而言并不是主干逻辑，可以通过 MQ 解耦，订单系统创建订单后发送消息，购物车系统消费消息清空购物车

- 扩展性，MQ 解耦了处理过程，所以增加消息入队和处理的频率是很容易的，扩展时不需要改代码、调节参数等
- 冗余，MQ 会把数据进行持久化知道它们被完全处理，从而规避了数据丢失风险
- 可恢复性，即使系统的某个消费者挂掉，加入队列的消息仍然可以在系统恢复后被处理
- 灵活性&峰值处理，可以在访问量剧增的情况下保护服务不被突发流量打崩溃
- 顺序保证，大多数场景下，数据处理的顺序都很重要，比如订单系统的状态流转。Kafka 保证了一个分区内消息的有序性
- 异步通讯，允许用户把消息放入 MQ 但并不立即处理，而是在需要的时候再处理
