最简单的架构：前端一台 Web 服务器运行业务代码，后端一台数据库服务器存储业务数据。

# 池化技术

池化技术的核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本。要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。

缺点：存储池子中的对象肯定需要消耗多余的内存，如果对象没有被频繁使用，就会造成内存上的浪费；池子中的对象需要在系统启动的时候就预先创建完成，这在一定程度上增加了系统启动时间。

**使用数据库连接池解决频繁创建连接带来的性能问题，使用线程池提升了并行查询数据库的性能。**

## 数据库连接池

在做了一次全网的流量推广后，系统的访问速度开始变慢。分析程序的日志之后，发现系统慢的原因出现在和数据库的交互上。

数据库的调用方式是先获取数据库的连接，然后依靠这条连接从数据库中查询数据，最后关闭连接释放数据库资源。这种调用方式下，每次执行 SQL 都需要重新建立连接，所以频繁地建立数据库连接耗费时间长导致了访问慢的问题。

上述问题的解决方案：**使用连接池将数据库连接预先建立好**，这样在使用的时候就不需要频繁地创建连接了。

数据库连接池有两个最重要的配置：最小连接数和最大连接数。对于数据库连接池，一般在线上建议最小连接数控制在 10 左右，最大连接数控制在 20 ～ 30 左右即可。

```
如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；
如果连接池中有空闲连接则复用空闲连接；
如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；
如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（C3P0 的连接池配置是 checkoutTimeout）等待旧的连接可用；
如果等待超过了这个设定时间则向用户抛出错误。
```

需要注意池子中连接的维护问题，一般出现问题的原因可能有：

- 数据库的域名对应的 IP 发生变更，池子的连接还是使用旧的 IP
  - 当旧的 IP 下的数据库服务关闭后，再使用这个连接查询就会发生错误
- MySQL 有个参数是“wait_timeout”，控制着当数据库连接闲置多长时间后，数据库会主动地关闭这条连接
  - 这个机制对于数据库使用方是无感知的，所以当我们使用这个被关闭的连接时就会发生错误。

那么，该如何保证池子中的连接一定可用呢？

- 启动一个线程来定期检测连接池中的连接是否可用
  - 如，使用连接发送`select 1`的命令给数据库看是否会抛出异常，如果抛出异常则将这个连接从连接池中移除，并且尝试关闭。
- 在获取到连接之后，先校验连接是否可用，如果可用才会执行 SQL 语句
  - 如，DBCP 连接池的 testOnBorrow 配置项用于控制是否开启这个验证
  - 这种方式在获取连接时会引入多余的开销，在线上系统中还是尽量不要开启，在测试服务上可以使用。

## 线程池

如果某个非常重要的接口需要多次访问数据库，那么这里未来也可能成为瓶颈。创建多个线程来并行处理与数据库之间的交互，但是这样的话，在高并发阶段，频繁创建线程的开销也会很大，类似数据库连接池，可以使用线程池来解决问题。

JDK 中的 ThreadPoolExecutor 就是一种线程池，它优先把任务放入队列暂存起来，而不是创建更多的线程。这种线程池比较适用于执行 CPU 密集型的任务！

```
如果线程池中的线程数少于 coreThreadCount 时，处理新的任务时会创建新的线程；
线程数大于 coreThreadCount 则把任务丢到一个队列里面，由当前空闲的线程执行；
当队列中的任务堆积满了的时候，则继续创建线程，直到达到 maxThreadCount；
当线程数达到 maxTheadCount 时还有新的任务提交，那么我们就不得不将它们丢弃了
```

因为执行 CPU 密集型的任务时 CPU 比较繁忙，因此只需要创建和 CPU 核数相当的线程就好了，多了反而会造成线程上下文切换，降低任务执行效率。所以当前线程数超过核心线程数时，线程池不会增加线程，而是放在队列里等待核心线程空闲下来。

而平时的 Web 系统中，通常都有大量的 IO 操作，如查询数据库、查询缓存等，任务在执行 IO 操作的时候 CPU 就空闲了下来，这时如果增加执行任务的线程数而不是把任务暂存在队列中，就可以在单位时间内执行更多的任务，大大提高了任务执行的吞吐量。Tomcat 使用的线程池就不是 JDK 原生的线程池，而是做了一些改造，当线程数超过 coreThreadCount 之后会优先创建线程，直到线程数到达 maxThreadCount，这样就比较适合于 Web 系统大量 IO 操作的场景了。

**线程池中使用的队列的堆积量也是我们需要监控的重要指标，对于实时性要求比较高的任务来说，这个指标尤为关键**。

**如果使用线程池请一定记住不要使用无界队列（即没有设置固定大小的队列）**。大量的任务堆积会占用大量的内存空间，一旦内存空间被占满就会频繁地触发 Full GC，造成服务不可用

# 高性能数据库集群

互联网业务兴起之后，海量用户加上海量数据的特点，单个数据库服务器已经难以满足业务需要，依据一些云厂商的 Benchmark 的结果，在 4 核 8G 的机器上运行 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS。

必须考虑数据库集群的方式来提升性能。

- 读写分离：本质是将访问压力分散到集群中的多个节点，但是没有分散存储压力
- 分库分表：既可以分散访问压力，又可以分散存储压力

## 读写分离

读写分离的基本原理是**将数据库读写操作分散到不同的节点上**。其基本实现：

- 数据库服务器搭建主从集群，一主一从、一主多从都可以。
- 数据库主机负责读写操作，从机只负责读操作。
- 数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。
- 业务服务器将写操作发给数据库主机，将读操作发给数据库从机。

注：这里是“主从集群”，而不是“主备集群”。**“从机”是需要提供读数据的功能的；而“备机”一般被认为仅仅提供备份功能，不提供访问功能。**

主从一致性和写入性能的权衡：如果要保证所有从节点都写入成功，那么写入性能一定会受影响；如果只写入主节点就返回成功，那么从节点就有可能出现数据同步失败的情况，从而造成主从不一致，而在互联网的项目中，一般会优先考虑性能而不是数据的强一致性。

读写分离会引入两个设计复杂度：主从复制延迟和分配机制。

### 主从复制延迟

[MySQL 的主从复制](../../DataBase(MySQL)/05-主从复制.md)

主从复制延迟会带来一个问题：如果业务服务器将数据写入到数据库主服务器后立刻（1 秒内）进行读取，此时读操作访问的是从机，主机还没有将数据复制过来，到从机读取数据是读不到最新数据的，业务上就可能出现问题。

常见解决办法：

- 使用缓存
  - 在同步写数据库的同时，也把数据写入到缓存里面，这样队列处理机在获取数据时候会优先查询缓存，也可以保证数据的一致性。
  - 更适合新增数据的场景
- 写操作后的读操作指定发给数据库主服务器
  - 这种方式和业务强绑定，对业务的侵入和影响较大。
- 读从机失败后再读一次主机，即二次读取
  - 二次读取和业务无绑定，只需要对底层数据库访问的 API 进行封装即可，实现代价较小
  - 不足之处在于如果有很多二次读取，将大大增加主机的读操作压力。如，黑客暴力破解账号，会导致大量的二次读取操作，主机可能顶不住读操作的压力从而崩溃。
- 关键业务读写操作全部指向主机，非关键业务采用读写分离

一般会把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。

### 分配机制

读写操作区分开来，然后访问不同的数据库服务器，一般有两种方式：程序代码封装和中间件封装。

- 程序代码封装
  - 程序代码封装指在代码中抽象一个数据访问层，实现读写操作分离和数据库服务器连接的管理。
  - 特点：
    - 实现简单，而且可以根据业务做较多定制化的功能。
    - 每个编程语言都需要自己实现一次，无法通用，如果一个业务包含多个编程语言写的多个子系统，则重复开发的工作量比较大。
    - 故障情况下，如果主从发生切换，则可能需要所有系统都修改配置并重启。
- 中间件封装
  - 独立一套系统出来，实现读写操作分离和数据库服务器连接的管理。
  - 中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离
  - 特点：
    - 能够支持多种编程语言，因为数据库中间件对业务服务器提供的是标准 SQL 接口。
    - 数据库中间件要支持完整的 SQL 语法和数据库服务器的协议，实现比较复杂，需要较长的时间才能稳定。
    - 数据库中间件自己不执行真正的读写操作，但所有的数据库操作请求都要经过中间件，中间件的性能要求也很高。
    - 数据库主从切换对业务服务器无感知，数据库中间件可以探测数据库服务器的主从状态。例如，向某个测试表写入一条数据，成功的就是主机，失败的就是从机。

数据库中间件的复杂度要比程序代码封装高出一个数量级，一般情况下建议采用程序语言封装的方式，或者使用成熟的开源数据库中间件。

## 分库分表

当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在这几个方面：

- 数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，性能同样会下降；
- 数据文件会变得很大，数据库备份和恢复需要耗费很长时间；
- 数据文件越大，极端情况下丢失数据的风险越高（例如，机房火灾导致数据库主备机都发生故障）。

所以，单个数据库服务器存储的数据量不能太大。为了满足业务数据存储的需求，就需要将存储分散到多台数据库服务器上。经历过分库分表后的系统，才能够突破单机的容量和请求量的瓶颈！

### 业务分库

除了上述的问题外，不同模块的数据全部存储在一个主库里，一旦主库发生故障，所有模块都会受到影响，那么该如何做到不同模块的故障隔离呢？

业务分库指的是按照业务模块将数据分散到不同的数据库服务器，这样一旦数据库发生故障时只会影响到某一个模块的功能，不会影响到整体功能，从而实现了数据层面的故障隔离。

业务分库可以分散存储压力和访问压力，却会带来以下问题：

- join 操作问题
  - 原本在同一个数据库中的表分散到不同数据库中，导致无法使用 SQL 的 join 查询。
- 事务问题
  - 原本在同一个数据库中不同的表可以在同一个事务中修改，业务分库后，表分散到不同的数据库中，无法通过事务统一修改
  - 虽然数据库厂商提供了一些分布式事务的解决方案（例如，MySQL 的 XA），但性能太低，与高性能存储的目标相违背。
- 成本问题
  - 本来 1 台服务器搞定的事情，现在要 3 台，如果考虑备份，那就是 2 台变成了 6 台。

### 分表

将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。

单表数据拆分有两种方式：

- 垂直拆分的关注点在于业务相关性
- 水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点

分表能够有效地分散存储压力和带来性能提升，但和分库一样，也会引入各种复杂性。

垂直分表

- 适合将表中某些不常用且占了大量空间的列拆分出去。
- 其引入的复杂性主要体现在表操作的数量要增加。
  - 原来只要一次查询就可以获取 name、age、sex、nickname、description，现在需要两次查询，一次查询获取 name、age、sex，另外一次查询获取 nickname、description。

水平分表

- 适合表行数特别大的表。
- 路由问题：水平分表后，某条数据具体属于哪个切分后的子表，需要增加路由算法进行计算
  - 范围路由：选取有序的数据列（例如，整形、时间戳等）作为路由的条件，不同分段分散到不同的数据库表中。
    - 设计的复杂点主要体现在分段大小的选取上
      - 分段太小会导致切分后子表数量过多，增加维护复杂度；
      - 分段太大可能会导致单表依然存在性能问题
      - 一般建议分段大小在 100 万至 2000 万之间，具体需要根据业务选取合适的分段大小。
    - 优点是可以随着数据的增加平滑地扩充新的表。
      - 例如，现在的用户是 100 万，如果增加到 1000 万，只需要增加新的表就可以了，原有的数据不需要动
    - 隐含的缺点是分布不均匀
      - 如按照 1000 万来进行分表，可能某个分段实际存储的数据量有 1000 条，另外一个分段实际存储的数据量有 900 万条。
  - Hash 路由：选取某个列（或者某几个列组合也可以）的值进行 Hash 运算，然后根据 Hash 结果分散到不同的数据库表中
    - 复杂点主要体现在初始表数量的选取上，表数量太多维护比较麻烦，表数量太少又可能导致单表性能存在问题。
    - 优点是表分布比较均匀
    - 缺点是扩充新的表很麻烦，所有数据都要重分布。
  - 配置路由：用一张独立的路由表来记录路由信息
    - 使用起来非常灵活，尤其是在扩充表的时候，只需要迁移指定的数据，然后修改路由表就可以了。
    - 缺点就是必须多查询一次，会影响整体性能；而且路由表本身如果太大（例如，几亿条数据），性能同样可能成为瓶颈
- join 操作
  - 水平分表后，数据分散在多个表中，如果需要与其他表进行 join 查询，需要在业务代码或者数据库中间件中进行多次 join 查询，然后将结果合并。
- count 操作
  - 水平分表后，虽然物理上数据分散到多个表中，但某些业务逻辑上还是会将这些表当作一个表来处理。
  - 获取记录总数用于分页或者展示，分表前使用一个 count 就能完成，分表后就复杂了，有以下两种方式
    - count 相加：在业务代码或者数据库中间件中对每个表进行 count 操作，然后将结果相加。
      - 性能比较低，如平分表后切分为 20 张表，则要进行 20 次 count 操作
    - 新建一张记录数表，每次插入或者删除子表数据成功后，都更新记录数表
      - 性能相比上一种方式好，只要一次查询即可
      - 增加了数据库的写压力，因为每次针对子表的 insert 和 delete 操作都要 update 记录数表
- order by 操作
  - 水平分表后，数据分散到多个子表中，排序操作无法在数据库中完成，只能由业务代码或者数据库中间件分别查询每个子表中的数据，然后汇总进行排序。

# 主键的全局唯一性

分布式存储的两个核心问题：数据冗余和数据分片。解决方式：

- 当面临高并发的查询数据请求时，可以使用主从读写分离的方式，部署多个从库分摊读压力；
- 当存储的数据量达到瓶颈时，可以将数据分片存储在多个节点上，降低单个存储节点的存储压力

通过分库分表和主从读写分离的方式解决了数据库的扩展性问题，除了之前提到的问题，其实分库分表还有一个问题，即**主键的全局唯一性**。

## 主键选取

数据库的主键一般有两种方式选取：

1. 使用业务字段作为主键，比如说对于用户表来说，可以使用手机号，email 或者身份证号作为主键；
2. 使用生成的唯一 ID 作为主键。

大部分场景中，方式一并不适用。如评论表中很难找到一个业务字段用于唯一标识这条评论；用户表的手机号、email 是可变的，也不适合，尽管身份证确实可以唯一标识用户，但其具有隐私属性，并不是用户系统的必须属性，如果不需要实名认证那就不需要身份证字段。且身份证也可能会变，1999 年身份证由 15 位变更为 18 位。

使用生成的唯一 ID 作为主键，一旦生成就不会变更，且可随意引用。单库单表下使用自增字段作为 ID，但是分库分表后，自增字段只能保证在当前库中唯一，而无法保证全局唯一性了。

## UUID

UUID(Universally Unique Identifier，通用唯一标识码)不依赖于任何第三方系统，在性能和可用性上都比较好，但存在以下缺点：

- UUID 不是单调递增的
  - ID 最好是单调递增的，即具有有序性，因为系统设计时，ID 有可能成为排序的字段。
    - 获取评论时，要按照时间倒序排列，而 ID 在时间上是有序的，所以可以按照评论的 ID 倒序排列，如果理论 ID 不是时间上有序的，就需要在评论列表中再存储一个多余的创建时间的列用作排序
  - ID 有序可以提高数据的写入性能
    - 类似有序数组，如果 ID 有序的话每次加到后面即可，而如果无序的话，插入时需要搬移其他数据
- UUID 不具备业务含义
  - 类似身份证号，固定位置的数字代表了特殊的意义。如果生成的 ID 可以被反解出来，对其进行验证，即可得知该 ID 是从哪个机房的发号机在什么时间生成的、是为哪个业务服务的，有助于排查问题。
- UUID 是由 32 个 16 进制数字组成的字符串，如果作为数据库主键使用比较耗费空间

## Snowflake 算法

Snowflake 的核心思想是将 64bit 的二进制数字分成若干部分，每一部分都存储有特定含义的数据，如时间戳、机器 ID、序列号等。

标准算法：41 位时间戳 + 10 位机器 ID +12 位序列号。其中最左侧保留一位不使用。

41 位的时间戳可以支持 $2^{41}/1000/60/60/24/365$ 大约 69 年。

可根据自身业务特点对算法进行改造。如加入业务 ID 字段来区分不同的业务。

两种使用方式：

- 嵌入到业务代码里，即分布在业务服务器中。
  - 业务代码在使用的时候不需要跨网络调用，性能上会好一些
  - 需要更多的机器 ID 位数来支持更多的业务服务器
  - 由于业务服务器的数量很多，很难保证机器 ID 的唯一性，所以就需要引入 ZooKeeper 等分布式一致性组件来保证每次机器重启时都能获得唯一的机器 ID。
- 作为独立的服务部署，这也就是常说的发号器服务
  - 业务在使用发号器的时候就需要多一次的网络调用，但是内网的调用对于性能的损耗有限，却可以减少机器 ID 的位数
  - 如果发号器以主备方式部署，同时运行的只有一个发号器，那么机器 ID 可以省略，这样可以留更多的位数给最后的自增信息位
  - 如果需要机器 ID，因为发号器部署实例数有限，可以把机器 ID 写在发号器的配置文件里，这样可以保证机器 ID 唯一性，也无需引入第三方组件了

Snowflake 算法依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止。

如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。解决方法：

- 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均
- 生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量地均衡了。

# 高性能 NoSQL

关系型数据库缺点：

- 存储的是行记录，无法存储数据结构
- 表结构 schema 是强约束，扩展不方便：
  - 操作不存在的列会报错；
  - 业务变化时扩充列也比较麻烦，需要执行 DDL 语句修改，而且修改时可能会长时间锁表(MySQL 可能将表锁住 1 个小时)
- 在大数据场景下 I/O 较高
  - 即使只针对其中某一列进行运算，关系数据库也会将整行数据从存储设备读入内存。
- 全文搜索功能比较弱
  - 关系数据库的全文搜索只能使用 like 进行整表扫描匹配，性能非常低

NoSQL(Not Only SQL)：**泛指非关系型的数据库**。常见的 NoSQL 方案分为四类：

- K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。
  - Key 是数据的标识，和关系数据库中的主键含义一样，Value 就是具体的数据
  - 相比于传统的数据库的优势是极高的读写性能，一般**对性能有比较高的要求的场景会使用**
- 文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。
  - no-schema，可以存储和读取任意的数据
  - 绝大部分文档数据库存储的数据格式是 JSON（或 BSON）
    - 因为 JSON 数据是自描述的，无须在使用前定义字段，读取一个 JSON 中不存在的字段也不会导致 SQL 那样的语法错误。
  - 新增字段简单，无需先执行 DDL 修改表结构
  - 历史数据不会出错
    - 历史数据即使没有新增的字段，也不会导致错误，只会返回空值，代码进行兼容处理即可。
  - 易存储复杂数据
  - 不支持事务、无法实现关系型数据库的 join 操作
- 列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。
  - 按照列来存储数据的数据库
  - 一般应用在离线的大数据分析和统计场景中，因为这种场景主要针对部分列单列进行操作，且数据写入后就无须再更新删除。
  - 节省 I/O
    - 场景：海量数据进行统计，如计算某个城市体重超重的人员数据时，只需要体重这一列进行统计
      - 行式存储即使最终只使用一列，也会将所有行数据都读取出来
      - 采用列式存储，每个用户只需要读取体重数据即可，I/O 将大大减少。
  - 具备更高的存储压缩比，能够节省更多的存储空间
    - 因为单个列的数据相似度相比行来说更高，能够达到更高的压缩率
  - 列式存储的随机写效率要远远低于行式存储的写效率
    - 列式存储将不同列存储在磁盘上不连续的空间，如果要频繁更新多列，此时磁盘是随机写操作
    - 而行式存储时同一行多个列都存储在连续的空间，一次磁盘写操作就可以完成
- 全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表
