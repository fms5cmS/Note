一体化架构在项目初期的优点：开发简单直接，代码和项目集中式管理；只需要维护一个工程，节省维护系统运行的人力成本；排查问题的时候，只需要排查这个应用进程就可以了，目标性强。

随着功能越来越复杂，开发团队越来越大，一体化架构的缺陷主要体现在：

- 技术层面上，数据库连接数可能成为系统瓶颈

数据库的连接是比较重的一类资源，连接过程比较耗时，而且连接 MySQL 的客户端数量有限制，最多可以设置为 16384（在实际的项目中，可以依据实际业务来调整）

由于系统是一体化架构部署的，结构上没有分层，应用服务器直接连接数据库，当前端请求量增加，部署的应用服务器扩容，数据库的连接数也会大增：

假设应用服务器部署在虚拟机上 50 个，每个服务会和数据库建立 30 个连接，但实际数据库连接数却远大于 1500。因为不仅要支撑来自客户端的外网流量还要部署单独的应用服务支撑来自其它部门的内网调用，也要部署队列处理机处理来自消息队列的消息，这些服务也都是与数据库直接连接的。所以一旦遇到大的运营推广活动服务器就要扩容，数据库连接数也随之增加，很可能回影响服务的稳定。

- 增加了研发成本，抑制了研发效率的提升

团队拆分为多个组来共同维护同一套代码和系统时，由于沟通问题，配合过程就会出现问题，且代码部署在一起，每个人都向同一个代码库提交，代码冲突无法避免，且功能之间耦合严重，小的改动可能回导致其他功能不可用。

- 影响系统运维，系统部署成本越来越高。

# 微服务架构

即使一体化架构做了垂直分库，但是当前端请求量越来越大时，由于每个业务模块都需要链接数据库从中获取数据，再加上请求量很大，就会导致用户库的连接数比其他库都要多，很容易成为系统瓶颈。

可以把与用户相关的逻辑部署成一个单独的服务，而其他业务模块都连接这个服务来获取和更改用户信息，即只有这个服务可以连接用户库，其它的业务池都不直连用户库获取数据。

由于这个服务只处理和用户相关的逻辑，所以不需要部署太多实例就可以承担流量，这样就可以有效地控制用户库的连接数，提升了系统的可扩展性。这样，就**按照业务做横向拆分**的方式解决了数据库层面的扩展性问题。

同样的，也可以**将与业务无关的公用服务抽取出来，下沉成单独的服务**。

通过以上两种拆分方式将系统拆分后，每一个服务的功能内聚，维护人员职责明确，增加了新的功能只需要测试自己的服务就可以了，而一旦服务出了问题，也可以通过服务熔断、降级的方式减少对于其他服务的影响。

## 架构改造

- 服务化拆分原则

**单一服务内部功能的高内聚和低耦合**：每个服务只完成自己职责之内的任务，对于不是自己职责的功能交给其它服务来完成。

如内容服务中，用户为认证用户的话就提升内容权重，这里判断用户是否为认证用户的逻辑应内聚再用户服务内部，而不能再内容服务中判断，否则认证的逻辑一旦变更内容服务也需要一同跟着变更。

**关注服务拆分的粒度，先粗略拆分再逐渐细化**：服务个数太多会增加运维成本；原本一次请求只需调用进程内多个方法，现在需要跨网络调用多个 RPC 服务，在性能上也会下降。

**拆分的过程，要尽量避免影响产品的日常功能迭代**：要一边做产品功能迭代，一边完成服务化拆分。

优先剥离比较独立的边界服务（比如短信服务、地理位置服务），从非核心的服务出发减少拆分对现有业务的影响，也给团队一个练习、试错的机会；

当两个服务存在依赖关系时优先拆分被依赖的服务。比如内容服务依赖于用户服务获取用户的基本信息，先拆分用户服务。

**服务接口的定义要具备可扩展性**，服务接口的参数类型最好是封装类，这样如果增加参数就不必变更接口的签名，而只需要在类中添加字段就可以了。

- 问题&解决思路

微服务化只是一种架构手段，有效拆分后可以帮助实现服务的敏捷开发和部署。但是由于将原本一体化架构的应用拆分成了多个通过网络通信的分布式服务，为了在分布式环境下协调多个服务正常运行，就必然引入一定的复杂度，这些复杂度主要体现在以下几个方面：

1. 服务接口的调用不再是同一进程内的方法调用而是跨进程的网络调用，这会增加接口响应时间的增加。需要选择高效的服务调用框架，同时接口调用方需要知道服务部署在哪些机器的哪个端口上，这些信息需要存储在一个分布式一致性的存储中。可以**引入服务注册中心**，注册中心管理服务完整的生命周期，包括对于服务存活状态的检测。
2. 多个服务之间杂的依赖关系较复杂。一旦被依赖的服务的性能出现问题产生大量的慢请求，就会导致依赖服务的工作线程池中的线程被占满，依赖的服务也会出现性能问题。接下来问题就会沿着依赖网逐步向上蔓延，直到整个系统出现故障为止。**引入服务治理体系**针对出问题的服务采用熔断、降级、限流、超时控制的方法，使问题被限制在单一服务中，保护服务网络中的其它服务不受影响。
3. 服务拆分到多个进程后，一条请求的调用链路上涉及多个服务，那么一旦这个请求的响应时间增长或者是出现错误，很难知道是哪一个服务出现的问题。**引入分布式追踪工具，以及更细致的服务端监控报表。**

监控报表关注的是依赖服务和资源的宏观性能表现；分布式追踪关注的是单一慢请求中的性能瓶颈分析，两者需要结合起来帮助你来排查问题。

## 服务治理

服务治理(service governance)就是是服务的管理，也就是解决多个服务节点组成集群的时候产生的一些复杂的问题。服务的注册和发现也是服务治理中的一环。

如果把集群看作是一个微型的城市，把道路看作是组成集群的服务，把行走在道路上的车看作是流量，那么服务治理就是对于整个城市道路的管理。

如果新建了一条街道（相当于启动了一个新的服务节点），那么就要通知所有的车辆（流量）有新的道路可以走了；你关闭了一条街道，你也要通知所有车辆不要从这条路走了，这就是**服务的注册和发现**。

在道路上安装监控，监视每条道路的流量情况，这就是**服务的监控**。

道路一旦出现拥堵或者道路需要维修，那么就需要暂时封闭这条道路，由城市来统一调度车辆，走不堵的道路，这就是**熔断以及引流**。

道路之间纵横交错四通八达，一旦在某条道路上出现拥堵，但是又发现这条道路从头堵到尾，说明事故并不是发生在这条道路上，那么就需要从整体链路上来排查事故究竟处在哪个位置，这就是**分布式追踪**。

不同道路上的车辆有多有少，那么就需要有一个警察来疏导，在某一个时间走哪一条路会比较快，这就是**负载均衡**。

# RPC框架

服务拆分单独部署后，会引入服务跨网络通信的问题。可以通过 RPC 框架解决。

RPC(Remote Procedure Call，远程过程调用)，指的是通过网络调用另一台计算机上部署服务的技术。

RPC 调用步骤：

1. 在一次 RPC 调用过程中，客户端首先会将调用的类名、方法名、参数名、参数值等信息，序列化成二进制流；
2. 然后客户端将二进制流通过网络发送给服务端；
3. 服务端接收到二进制流之后将它反序列化，得到需要调用的类名、方法名、参数名和参数值，再通过动态代理的方式调用对应的方法得到返回值；
4. 服务端将返回值序列化，再通过网络发送给客户端；
5. 客户端对结果反序列化之后，就可以得到调用的结果了。

场景：假设 QPS 已经达到了每秒 2 万次，在做了服务化拆分之后，由于我们把业务逻辑都拆分到了单独部署的服务中，如果完成一次完整的请求需要调用 4～5 次服务，计算下来，RPC 服务需要承载大概每秒 10 万次的请求。而你该如何设计 RPC 框架承载如此大的请求量呢？

- 选择合适的网络模型，有针对性地调整网络参数优化网络传输性能；
- 选择合适的序列化方式，以提升封包、解包的性能。

## 优化网络传输

- 选择一种高性能的 [I/O 模型](../../Common/IO)，如同步多路 I/O 复用
- 网络参数调优，以  tcp_nodelay 参数为例

TCP 协议的包头有 20 字节，IP 协议的包头也有 20 字节，如果仅仅传输 1 字节的数据在网络上传输的就有 20 + 20 + 1 = 41 字节，其中真正有用的数据只有 1 个字节，这对效率和带宽是极大的浪费，Nagle`s 算法：

> 如果是连续的小数据包，大小没有一个 MSS(Maximum SegmentSize，最大分段大小)，并且还没有收到之前发送的数据包的 Ack 信息，那么这些小数据包就会在发送端暂存起来，直到小数据包累积到一个 MSS，或者收到一个 Ack 为止。

该算法原本是是为了减少不必要的网络传输，但如果接收端开启了 DelayedACK(延迟 ACK 的发送，这样可以合并多个 ACK，提升网络传输效率)，那就会发生发送端发送第一个数据包后接收端没有返回 ACK，这时发送端发送了第二个数据包，因为 Nagle`s 算法的存在，并且第一个发送包的 ACK 还没有返回，所以第二个包会暂存起来。而 DelayedACK 的超时时间默认是 40ms，所以一旦到了 40ms，接收端回给发送端 ACK，那么发送端才会发送第二个包，这样就增加了延迟。

解决方法：在 Socket 上开启 tcp_nodelay 就好了，这个参数关闭了 Nagle`s 算法，这样发送端就不需要等到上一个发送包的 ACK 返回直接发送新的数据包就好了。这对于强网络交互的场景来说非常适用。

## 合适的序列化方式

一次 RPC 调用需要经历两次数据序列化的过程和两次数据反序列化的过程，可见它们对于 RPC 的性能影响是很大的，那么我们在选择序列化方式的时候需要考虑哪些因素呢？

- 性能，包括时间上的开销和空间上的开销
  - 时间上的开销就是序列化和反序列化的速度
  - 空间上的开销则是序列化后的二进制串的大小，过大的二进制串也会占据传输带宽影响传输效率
- 是否可以跨语言、跨平台
  - 如果 RPC 框架中传输的数据只能被一种语言解析，这无疑限制了框架的使用
- 扩展性
  - 扩展性差的话，对象增加了一个字段就会造成传输协议的不兼容，导致服务调用失败

序列化可选方案：

- JSON
  - 对于性能要求不高，在传输数据占用带宽不大的场景下可以使用
- Thrift 和 Protobuf 
  - 都需要引入 IDL(Interface description language)，也就是需要按照约定的语法写一个 IDL 文件，然后通过特定的编译器将它转换成各语言对应的代码，从而实现跨语言的特点
  - 无论是空间还是时间都有很高性能，但由于 IDL，使用上会不太方便
  - Thrift 提供了配套的 RPC 框架，可以优先考虑 Thrift；
  - 在一些存储的场景下，如缓存中存储的数据占用空间较大，可以考虑使用 Protobuf

# 注册中心

服务注册和发现不是一个新的概念，如 Nginx 是一个反向代理组件，那么 Nginx 需要知道应用服务器的地址是什么，这样才能够将流量透传到应用服务器上，这就是服务发现的过程。

Nginx 是通过把应用服务器的地址配置在了文件中实现的。RPC 服务端的地址也这样做会存在一些问题：

- 在紧急扩容的时候，就需要修改客户端配置后，重启所有的客户端进程，操作时间比较长；
- 某一个服务器出现故障时，也需要修改所有客户端配置后重启，无法快速修复，更无法做到自动恢复；
- RPC 服务端上线无法做到提前摘除流量，这样在重启服务端的时候，客户端发往被重启服务端的请求还没有返回，会造成慢请求甚至请求失败。

可以考虑使用**注册中心**解决这些问题。注册中心组件：ZooKeeper、Kubernetes 使用的 ETCD、阿里的微服务注册中心 Nacos、Spring Cloud 的 Eureka 等。基本功能：

- 提供服务地址的存储
- 当存储内容发生变化时，将变更的内容推送到客户端

服务注册和发现的过程：

1. 客户端会与注册中心建立连接，并且告诉注册中心，它对哪一组服务感兴趣；
2. 服务端向注册中心注册服务后，注册中心会将最新的服务注册信息通知给客户端；
3. 客户端拿到服务端的地址之后就可以向服务端发起调用请求了。

有了注册中心之后，服务节点的增加和减少对于客户端就是透明的。这样除了可以实现不重启客户端就能动态地变更服务节点以外，还可以实现优雅关闭的功能。

如果暴力地停止服务，那么已经发送给服务端的请求，来不及处理服务就被删掉了，就会造成这部分请求失败，服务就会有波动。所以服务在退出的时候，都需要先停掉流量再停止服务，这样服务的关闭才会更平滑。比如，消息队列处理器就是要将所有已经从消息队列中读出的消息，处理完之后才能退出。

对于 RPC 服务来说，可以先将 RPC 服务从注册中心的服务列表中删除掉，然后观察 RPC 服务端没有流量之后，再将服务端停掉。有了优雅关闭之后，RPC 服务端再重启的时候，就会减少对客户端的影响。

## 服务状态管理

服务的上线和下线是由服务端主动向注册中心注册和取消注册来实现的，但是如果某个服务端意外故障，服务端就没有办法向注册中心通信，将自己从服务列表中删除，那么客户端也就不会得到通知，它就会继续向一个故障的服务端发起请求，也就会有错误发生了。这种情况如何来避免呢？

思路一：主动探测

RPC 服务要打开一个端口，然后由注册中心每隔一段时间（比如 30 秒）探测这些端口是否可用，如果可用就认为服务仍然是正常的，否则就可以认为服务不可用，那么注册中心就可以把服务从列表里面删除了。

存在问题：

所有的 RPC 服务端都需要开放一个统一的端口给注册中心探测，那时候还没有容器化，一台物理机上会混合部署很多的服务，你需要开放的端口很可能已经被占用，这样会造成 RPC 服务启动失败；

如果 RPC 服务端部署的实例比较多，那么每次探测的成本也会比较高，探测的时间也比较长，这样当一个服务不可用时，可能会有一段时间的延迟，才会被注册中心探测到。

思路二：**心跳模式**

大部分注册中心都采用这种方式来检测连接上来的 RPC 服务端是否存活，比如 Eureka、ZooKeeper。

注册中心为每一个连接上来的 RPC 服务节点记录最近续约的时间，RPC 服务节点在启动注册到注册中心后，就按照一定的时间间隔（如 30s），向注册中心发送心跳包。注册中心在接收到心跳包之后，会更新这个节点的最近续约时间。然后，注册中心会启动一个定时器定期检测当前时间和节点最近续约时间的差值，如果达到一个阈值（如 90s），那么认为这个服务节点不可用。

## 可能出现的问题

- 服务节点被过度摘除

假设注册中心将信息都存储在 Redis 主库，而不同机房的注册中心，则从各自的 Redis 从库中获取最近续约时间，从而判断服务节点是否有效。

Redis 主从同步延迟会导致部分从库存储的最近续约时间就没有得到及时更新，如果延迟严重，注册中心发现了当前时间与最近续约时间的差值超过了摘除的阈值，可能会将所有的节点摘除，从而导致了故障。

可以给注册中心增加保护策略：如果摘除的节点占到了服务集群节点数的一定比例，就停止摘除服务节点，并且给服务的开发和运维人员报警处理。

Eureka 采用了类似的策略，来避免服务节点被过度摘除，导致服务集群不足以承担流量的问题。如果使用的是 ZooKeeper 或者 ETCD 这种无保护策略的分布式一致性组件，可以考虑在客户端，实现保护策略的逻辑，比如说当摘除的节点超过一定比例时，在 RPC 客户端就不再处理变更通知。

- 通知风暴

假如服务有 100 个调用者，有 100 个节点，那么变更一个节点会推送 100 * 100 = 10000 个节点的数据。那么如果多个服务集群同时上线或者发生波动时，注册中心推送的消息就会更多，会严重占用机器的带宽资源。

1. 控制一组注册中心管理的服务集群的规模，具体规模需要结的业务以及注册中心的选型来考虑，主要考察的指标就是注册中心服务器的峰值带宽；
2. 可以通过扩容注册中心节点的方式来解决；
3. 可以规范一下对于注册中心的使用方式，如果只是变更某一个节点，那么只需要通知这个节点的变更信息即可；
4. 自建的注册中心，可以在其中加入一些保护策略，比如说如果通知的消息量达到某一个阈值就停止变更通知。

