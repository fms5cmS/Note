# CPU 缓存

现在的 CPU 都是多核的，CPU 的缓存分为 L1、L2、L3 共三级缓存，其中 L3 是一颗 CPU 上所有核心共享的，而 L1、L2 则是每个核心独有的。程序执行时，会先将内存中的数据载入到共享的三级缓存中，再进入每颗核心独有的二级缓存，最后进入最快的一级缓存，之后才会被 CPU 使用。[存储器层次结构](https://time.geekbang.org/column/article/107422)。

[**局部性原理**](https://time.geekbang.org/column/article/107447)：

- 时间局部性：如果一个数据被访问了，那么它在短时间内还会被再次访问；
  - LRU 缓存算法，就利用了时间局部性，一段时间内被访问的数据还会在短期内再次访问，而长期不被访问的数据则会被移出缓存。
- 空间局部性：如果一个数据被访问了，那么和它相邻的数据也很快会被访问。

CPU 访问缓存比访问内存要快很多，如果可以**减少 CPU 访问内存的次数**，大部分数据都从缓存中读取，性能自然会提升很多。

> 要访问的数据可以在缓存中直接找到，这就是**缓存命中**。

所以代码优化的目标就是提升 CPU 的缓存命中率。CPU 的一级缓存分为两部分：数据缓存和指令缓存。

Linux 下有一个 perf 的工具(`yum install perf` 安装)，[使用示例](http://www.brendangregg.com/perf.html)。

## 提高数据缓存的命中率

```java
for(i = 0; i < N; i+=1) {
    for(j = 0; j < N; j+=1) {
        arr[i][j] = 0; // arr[j][i] = 0;
    }
}
```

二维数组 arr 所占用的内存是连续的，内存中各元素的顺序为：

```
arr[0][0]、arr[0][1]、arr[0][2]...arr[1][0]、arr[1][1]...
```

如果使用 `arr[i][j]` 访问数组的话，在访问 `arr[0][0]` 时，缓存就会把紧随其后的几个元素也载入，CPU 通过快速的缓存来读取后续 3 个元素就可以。如果用 `array[j][i]` 来访问，此时内存是跳跃访问的，如果长度 N 较大，那么每次访问 `arr[j][i]` 时都是通过访问内存来获取数据，而无法利用 CPU 缓存。

**遇到这种遍历访问数组的情况时，按照内存布局顺序访问将会带来很大的性能提升。**

如果可以利用 CPU 缓存的话，缓存每次会载入多少数据呢？这与 CPU Cache Line(缓存块) 有关，Cache Line 定义了缓存一次载入数据的大小，在 Linux 系统上，通过 `cat /sys/devices/system/cpu/cpu0/cache/index1/coherency_line_size` 可知其通常为 64 字节。[Cache 的数据结构与读取过程](https://time.geekbang.org/column/article/107477)。

在多线程并行访问数据时，如果知道缓存中的数据是否过期？这就是缓存一致性问题，[CPU 高速缓存的写入](https://time.geekbang.org/column/article/109331)、[MESI 协议](https://time.geekbang.org/column/article/109874)。

## 提高指令缓存的命中率

```go
  // 无序数组
	var arr [100]int
	for i := 0; i < 100; i++ {
		arr[i] = rand.Intn(1000)
	}
```

假设有一个无序的整型数组，要将所有小于 128 的元素值重置为 0，并进行排序。那么，是先遍历后排序快还是先排序后遍历快呢？答案是先排序更快。因为循环中有很多 if 条件分支，而 CPU 中含有[分支预测](https://time.geekbang.org/column/article/102166)。最简单的分支预测就是“假装分支不发生”，即 CPU 预测，条件跳转一定不发生。

当数组中的元素完全随机时，分支预测器无法有效工作，而当 arr 数组有序时，分支预测器会动态地根据历史命中数据对未来进行预测，命中率就会非常高。

## 提高多核 CPU 下的缓存命中率

现代分时操作系统都支持许多进程同时运行。因为操作系统把时间切成了许多片，微观上各进程按时间片交替地占用 CPU，这造成宏观上看起来各程序同时在执行。

每个进程只有在自己被调度到 CPU 的某个核心上的时间片里可以高效利用其一二级缓存，下一个时间片可能就会被让出 CPU，让其他的进程被调度，防止某些进程被饿死。

操作系统提供了将进程或线程绑定到某一颗 CPU 上运行的能力，如 Linux 上的 sched_setaffinity 方法。当多线程同时执行密集计算，且 CPU 缓存命中率很高时，如果将每个线程分别绑定在不同的 CPU 核心上，性能便会获得非常可观的提升。Perf 工具也提供了 cpu-migrations 事件，它可以显示进程从不同的 CPU 核心上迁移的次数。
