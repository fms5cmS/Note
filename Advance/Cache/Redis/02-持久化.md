Redis 所有数据保存在内存中，对数据的更新将异步保存到磁盘上。

主流数据库持久化的方式：

1. 快照：MySQL 的 Dump、Redis 的 RDB
2. 写日志：MySQL 的 Binlog、Hbase 的 Hlog、Redis 的 AOF

Redis 在 shutdown 时会自动进行持久化，但终止服务(如 kill 进程)不会进行持久化。



# RDB

RDB(Redis DataBase)：在指定的时间间隔内将内存中的数据集快照写入磁盘，即 Snapshot 快照，而恢复时是将快照文件直接读到内存里。

RDB 保存的是 dump.rdb 文件。如果存在老的 RDB 文件，会将其替换。

优势：

- 适合大规模的数据恢复，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。
- 对数据完整性和一致性要求不高
- 节省磁盘空间
- 恢复速度快

劣势：

- 在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改
- RDB 是耗时（会将所有数据写入rdb文件，是一个$O(N)$的过程）、耗性能（fork会消耗内存、如果rdb文件很大，会很消耗IO性能）的



## 相关配置

位于redis.conf文件的 SNAPSHOTTING 部分。默认配置：

```shell
save 900 1    
save 300 10
save 60 10000
#后台保存错误时，前台的写操作会停止
#如果配置成no，表示不在乎数据不一致或者有其他的手段发现和控制
stop-writes-on-bgsave-error yes 
#对于存储到磁盘中的快照，可以设置是否进行压缩存储。
#如果 yes 的话，Redis 会采用 LZF 算法进行压缩。
#如果不想消耗 CPU 来进行压缩的话，可以设置为关闭此功能
rdbcompression yes 
#在存储快照后，可以让 Redis 使用 CRC64 算法来进行数据校验，
#但这样做会增加性能消耗，如果希望获取到最大的性能提升，可以关闭此功能
rdbchecksum yes 
dbfilename dump.rdb #RDB持久化的文件名
dir ./   #工作目录，即RDB、AOF、日志文件的目录
```

------

最佳配置（根据个人需求决定，这里只是一个示例）：

```shell
#这三个配置是相对的，故这里不再设置，实际中很少使用
save 900 1
save 300 10
save 60 10000
# 可以以端口号来区分RDB文件
dbfilename dump-${port}.rdb
# 选择一个合适的路径
dir /bigdiskpath
# 如果bgsave发生错误，就停止写入
stop-writes-on-bgsave-error yes
# 对存储的快照采用压缩存储
rdbcompression yes
# 采用校验
rdbchecksum yes
```



## 三种触发方式

- `save` 命令：

只管保存，其他不管，全部阻塞。`save`后再终止服务，此时已经持久化到硬盘了。

---

- `bgsave`命令：在后台异步进行快照操作，快照同时还可以响应客户端请求。

可通过`lastsave`命令获取最后一次成功执行快照的时间。

Redis 会单独创建（fork）一个子进程来进行持久化，子进程先将数据写入一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能。

补充：fork 的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但却是一个全新的进程，并作为原进程的子进程。

---

- 自动触发（很少使用）：满足配置文件中任意一条配置策略都会触发，配置策略如下：

```shell
save 900 1    #900秒内发生一次更改
save 300 10    #300秒内发生10次更改
save 60 10000  #60秒内发生10000次更改
```

---

对比：

| 命令             | `save`           | `bgsave`                         |
| ---------------- | ---------------- | -------------------------------- |
| IO类型           | 同步             | 异步                             |
| 是否会发生阻塞？ | 是               | 是（阻塞发生在fork），但很少发生 |
| 复杂度           | $O(N)$           | $O(N)$                           |
| 优点             | 不会消耗额外内存 | 不阻塞客户端命令                 |
| 缺点             | 阻塞客户端命令   | 需要fork进程，消耗内存           |

其他不可忽略的方式：

- 全量复制(主从复制时，主会生成RDB文件)
- debug reload
- `shutdown`时也会生成RBD文件。

实际上，执行`flushall`命令，也会产生dump.rdb文件，但里面是空的，无意义。



## 恢复&停止

如何恢复数据呢？将备份文件 (dump.rdb) 移动到 Redis 安装目录并启动服务即可；

动态停止 RDB 保存规则的方法：`redis-cli config set save ""`



# AOF

AOF(Append Only File) **以日志的形式来记录每个写操作**，将 Redis 执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，Redis 启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

AOF保存的是 appendonly.aof 文件。如果是做缓存和存储，可以开启AOF。

优势：

- 备份机制更稳健，丢失数据概率更低
- 可读的日志文本，通过操作AOF文件，可以处理误操作

劣势：

- 相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb
- aof运行效率要慢于rdb,每秒同步策略效率较好，不同步效率和rdb相同



## 相关配置

位于redis.conf文件的 APPEND ONLY MODE部分。

```shell
appendonly no  #修改为yes开启AOF持久化
appendfilename "appendonly.aof" #AOF持久化文件名
appendfsync everysec #配置AOF策略
#重写时是否可以运用appendfsync，用默认no即可，保证数据安全性。
no-appendfsync-on-rewrite no 
#AOF文件重写需要的尺寸,即 64M 才开始重写，建议修改为较大数值
auto-aof-rewrite-min-size 64mb 
#AOF文件增长率，即发生重写后，下一次要达到多大才重写，默认100%
auto-aof-rewrite-percentage 100  
```



## 三种策略

Redis在执行写命令时，不是直接写在硬盘中，而是先写在硬盘的缓冲区中，缓冲区会根据一定策略将其刷新到硬盘中。

- appendfsync always(每修改同步)：同步持久化，即每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好
- appendfsync everysec(每秒同步)（默认）：异步操作，每秒记录一次，如果一秒内宕机，有数据丢失
- appendfsync no(不同步)：由操作系统决定何时将缓冲区 fsync 到硬盘的 aof 文件

| 命令 | always                              | everysec                          | no     |
| ---- | ----------------------------------- | --------------------------------- | ------ |
| 优点 | 不丢失数据                          | 每秒一次fsync；最多只丢失一秒数据 | 不用管 |
| 缺点 | IO开销较大，一般的sata盘只有几百TPS | 可能丢失一秒数据                  | 不可控 |



## AOF 重写

rewrite 重写：AOF 采用文件追加方式，文件会越来越大，为避免出现这种情况，新增了重写机制，当AOF文件大小超过所设定的阈值时，Redis 会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。

作用：减少硬盘占用量、加速恢复速度

类比说明AOF重写的作用：（这里的示例仅类似AOF重写，并不是AOF重写！）

| 原生AOF                                                     | AOF重写              |
| ----------------------------------------------------------- | -------------------- |
| `set hello world`<br/>`set hello java`<br/>`set hello hehe` | `set hello hehe`     |
| `incr counter`<br/>`incr counter`                           | `set counter 2`      |
| `rpush mylist a`<br/>`rpush mylist b`<br/>`rpush mylist c`  | `spush mylist a b c` |



重写有两种实现方式：

- `bgrewriteaof`命令：会 fork 出一个新进程来将 aof 文件重写。

重写 aof 文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 aof 文件，这点和快照有点类似。

---

- AOF 重写的配置：默认当 aof 文件大小是上次 rewrite 后大小的一倍且文件大于64M时触发

```shell
auto-aof-rewrite-min-size 64mb #AOF文件重写需要的尺寸,即 64M 才开始重写
#AOF文件增长率，即发生重写后，下一次要达到多大才重写，默认100%
auto-aof-rewrite-percentage 100  
```

如：设置达到100M时重写，增长率设置为100%，则第一次重写后，AOF文件不断增大，当达到200M时会再次发生重写。

Redis 提供了两个统计项(并不是配置)来记录AOF文件的大小：

- `aof_current_size`：AOF文件当前的尺寸（单位：字节）
- `aof_base_size`：AOF上次启动和重写的尺寸（单位：字节）

满足以下两个条件，会自动触发AOF重写

- `aof_current_size` > `auto-aof-rewrite-min-size`
- （`aof_current_size` - `aof_base_size`) / `aof_base_size` > `auto-aof-rewrite-percentage`



## 恢复

正常恢复的步骤：

1. 启动：修改默认的appendonly no为yes；
2. 将有数据的aof文件复制一份保存到对应目录(config get dir)
3. 恢复：重启redis然后重新加载

异常恢复的步骤：

1. 启动：修改默认的appendonly no，改为yes；
2. 备份被写坏的AOF文件
3. `redis-check-aof --fix aof文件`进行修复
4. 恢复：重启redis然后重新加载



# 对比

|              | RDB      | AOF          |
| ------------ | -------- | ------------ |
| 启动优先级   | 低       | 高           |
| 文件大小     | 小       | 大           |
| 恢复速度     | 快       | 慢           |
| 数据安全性   | 会丢数据 | 根据策略决定 |
| 该操作的轻重 | 重       | 轻           |



- RDB 持久化能在指定时间间隔对数据进行快照存储；
- AOF 持久化方式记录每次对服务器写的操作，当服务器重启时会重新执行这些命令来恢复原始数据，AOF 命令以 Redis 协议追加保存每次写操作到文件末尾，Redis 还能对 AOF 文件进行后台重写，使 AOF 文件体积不至于过大；
- 同时开启两种持久化方式：
  - **Redis 重启时会优先载入 AOF 文件来恢复原始数据**，因为通常情况下 AOF 文件保存的数据集更完整；
  - 建议**不要只使用 AOF**。因为 RDB 更适合于备份数据库(AOF 在不断变化不好备份)，可以快速重启，且不会有 AOF 可能潜在的bug。
- 性能建议：
  - 因为 RDB 文件只用作后备用途，建议只在 Slave 上持久化 RDB 文件，而且只要 15 分钟备份一次就够了，只保留 `save 900 1` 这条规则。
  - 如果开启 AOF
    - 好处是在最恶劣情况下也只会丢失不超过两秒数据。
    - 代价是带来了持续的 IO，且 AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少 AOF rewrite的频率，AOF 重写的基础大小默认值 64M 太小了，可以设到5G以上。
  - 如果不开启 AOF ，仅靠 Master-Slave Replication 实现高可用性也可以。
    - 能省掉一大笔 IO 也减少了rewrite时带来的系统波动。
    - 代价是如果 Master/Slave 同时 down 掉，会丢失十几分钟的数据。



# 补充

## fork 操作

fork 操作是一个同步操作，大部分情况下是很快的，但如果某次的fork操作很慢或卡在某个地方，就会阻塞 Redis 的主线程。

fork 操作的时间与内存量是相关的，内存越大，耗时越长；也与机器类型(虚拟机、物理机)有关。

改善 fork：

1. 优先使用物理机或高效支持 fork 操作的虚拟化技术；
2. 控制 Redis 实例最大可用内存：maxmemory；
3. 合理配置 Linux 内存分配策略，如：vm.overcommit_memory=1；
4. 降低 fork 频率：如放宽 AOF 重写自动触发时机，不必要的全量复制。



## 子进程开销&优化

子进程的开销与优化：

CPU：

- 开销：RDB和AOF文件生成，属于CPU密集型
- 优化：不做CPU绑定，不和CPU密集型应用部署在一起

内存：

- 开销：fork内存开销，copy-on-write
- 优化：echo never > /sys/kernel/mm/transparent_hugepage/enabled

硬盘：

- 开销：AOF和RDB文件写入，可以结合`iostat`、`iotop`分析
- 优化：
  - 不要和高硬盘负载服务(eg:存储服务、消息队列等)部署在一起
  - 在AOF重写期间不要进行正常的AOF追加的操作，配置：`no-appendfsync-on-rewrite=yes`
  - 根据写入量决定磁盘类型
  - 单机多实例持久化文件目录可以考虑分盘