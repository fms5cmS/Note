Redis命令的生命周期：

Client发送命令 ——> Redis对所有命令排队 ——> Redis逐个执行命令 ——> Redis向客户端返回结果。



# slowlog

slowlog 是 Redis 记录慢查询执行时间的日志系统。由于 slowlog 只**保存在内存**中，因此 slowlog 的效率很高，完全不用担心会影响到Redis的性能。

- 注意：
  - 慢查询发生在第三阶段；
  - 客户端超时不一定慢查询，但慢查询是客户端超时的一个可能因素；
  - 定期持久化慢查询。

一条命令在执行过程中成为慢查询，它就会被记录仅一个队列(使用Redis的List来实现的)，该队列是有固定长度的。

---

- 相关命令：

```shell
slowlog get [n] # 获取慢查询队列，通过可选参数n可以指定获取几条慢查询
slowlog len  # 获取慢查询队列长度，即队列中慢查询的个数
slowlog reset  # 清空慢查询队列
```

---

- 相关配置：

慢查询的两个配置：
- slowlog-log-slower-than 慢查询阈值(单位：微秒)，query的执行时间超过该值的才会被定义为慢查询，被slowlog记录。默认10000微妙，即10ms。
  - 不要设置过大，通常设置为1ms
- slowlog-max-len 是存放慢查询的队列的长度，即慢查询最大的条数，当slowlog超过设定的最大值后，会将最早的slowlog删除。默认是128
  - 不要设置过小，通常设置为1000左右

查看配置(需要进入Redis客户端命令行)
- `config getslowlog-max-len`
- `config getslowlog-log-slower-than`

修改配置：
- 方式一：动态配置(需要进入Redis客户端命令行)
  - `config set slowlog-max-len 1000`
  - `config set slowlog-log-slower-than 1000`
- 方式二：修改配置文件重启



# pipeline

一般而言，1次网络命令时间 = 1次网络时间 + 1次命令时间，而如果要执行多条命令的话，n次网络命令时间 = n次网络时间 + n次命令时间。

流水线：将多条命令打包，一次性通过网络发送给服务端，服务端逐个执行命令，再将打包后的结果一次性返回给客户端。所以：1次 pipeline(n条命令) = 1次网络时间 + n次命令时间。

注意：Redis的命令时间是微秒级别的；pipeline 每次条数要控制(网络环境制约)！

原生的m操作(如：mset)是原子操作；而 pipeline 的命令是非原子操作。

使用时要注意每次pipeline携带的数据量；且 pipeline 每次只能作用在一个 Redis 节点上。

---

- Jedis 来使用 pipeline

下面是执行10000次hset命令的示例。

没有pipeline时：

```java
Jedis jedis = new Jedis("127.0.0.1",6379);
for(int i=0; i<10000; i++){
    jedis.hset("hashkey:" + i , "field" + i , "value" + i);
}
```

使用pipeline时：

```java
Jedis jedis = new Jedis("127.0.0.1",6379);
for(int i=0; i<100; i++){
    Pipeline pipeline = jedis.pipelined();
    for(int j = i * 100; j < (i + 1) * 100; j++){
        pipeline.hset("hashkey:" + j , "field" + j , "value" + j);
    }
    pipeline.syncAndReturnAll();
}
```



# 发布/订阅

发布定阅是进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。

![](https://github.com/fms5cmS/MyNote/raw/master/images/Redis-message.png)

- 命令：

```shell
psubscribe pattern1 pattern2...  #订阅一个或多个给定模式的频道
pubsub subcommand 参数列表  #查看订阅与发布系统状态
publish channel message    #将信息发送到指定频道
punsubscribe pattern1 pattern2...  #退订所有给定模式的频道
subscribe channel1 channel2...  #订阅给定的一个或多个频道信息
unsubscribe channel1 channel2...  #退订给定的频道
```

案例：**先订阅后发布**后才能收到消息。

1. 可以一次性订阅多个：`SUBSCRIBE c1 c2 c3`
2. 消息发布：`PUBLISH c2 hello-redis`
3. 以通配符`*`的形式订阅多个以new开头的channel： `PSUBSCRIBE new*`
4. 收取消息： `PUBLISH new1 redis2015`



# Bitmap

位图。Redis可以直接操作键值对中value的二进制值。如`set hello world`，world在底层是以二进制的形式存储的，而可以通过API来操作底层的二进制。

- 对比

假设共有一亿用户，每天有五千万的用户独立访问。

| 数据类型 | 每个userid占用空间                       | 需要存储的用户量 | 全部内存量             |
| -------- | ---------------------------------------- | ---------------- | ---------------------- |
| Set      | 32位(即假设是整型,实际常用长整型)        | 50,000,000       | 32位*50,000,000=200MB  |
| Bitmap   | 1位(假设userid=10000，就将第10000位置一) | 100,000,000      | 1位*100,000,000=12.5MB |

如果只有十万独立用户呢？

| 数据类型 | 每个userid占用空间 | 需要存储的用户量 | 全部内存量             |
| -------- | ------------------ | ---------------- | ---------------------- |
| Set      | 32位               | 1,000,000        | 32位*1,000,000=4MB     |
| Bitmap   | 1位                | 100,000,000      | 1位*100,000,000=12.5MB |

---

- 命令

```shell
#给位图指定索引设置值
#如果本身位图仅有20位，而设置索引50时，20到50之间会设置默认的二进制值0
setbit key index value
# 获取位图指定索引的值
getbit key index
#获取位图指定范围(start到end，单位为字节，如果不指定就是获取全部)位值为1的个数
bitcount key [start end]
#做多个Bitmap的and(交集)、or(并集)、not(非)、xor(异或)操作并将结果保存在destkey中
bitop 操作 destkey key1 key2 ... 
#计算位图指定范围(start到end，单位为字节，如果不指定就是获取全部)第一个偏移量对应的值等于targetBit的位置
bitpos key targetBit [start] [end]
```



# HyperLogLog

基于HyperLogLog算法：极小空间完成独立数量统计。本质还是字符串。

命令：

```shell
pfadd key element1 element2 ... #向HyperLogLog添加元素
pfcount key1 key2 ... #计算HyperLogLog的独立总数
pfmerge destkey sourcekey1 sourcekey2... #合并多个HyperLogLog保存到destkey
```



# GEO

GEO(地理信息定位)：存储经纬度，计算两地距离、范围计算等。Redis 3.2之后实现的，底层使用Zset实现。

命令：

```shell
# 增加地理位置信息，如添加北京的经纬度：geoadd china 116.28 39.55 "beijing"
geoadd key longitude1 latitude1 member1 longitude2 latitude2 member2 ...
# 获取地理位置信息
geopos key member1 member2 ...
# 获取两个地理位置的距离，unit：m(米)、km(千米)、mi(英里)、ft(尺)
geolist key member1 member2 [unit]
# 可以使用Zset的删除命令来删除
zrem key member
# georadius 命令可以获取指定位置范围内的地理位置信息集合。较复杂，不再列出
```



# 事务

Redis事务的主要作用就是串联多个命令防止别的命令插队。分为三个阶段：

1. 开启：以 MULTI 开始一个事务；
2. 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面；
3. 执行：由 EXEC 命令触发事务

特性：

- 单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断；
- 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题
- 不保证原子性(部分支持事务)：Redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚



## 事务命令

- `multi`标记一个事务块的开始
- `discard`取消事务
- `exec`执行所有事务块内的命令
- `unwatch`取消watch命令对所有key的监视
- `watch key1 key2...`监视一个或多个key，如果在事务执行前这些key被其他命令改动，那么事务将会被打断

1. 正常执行

   ```shell
   MULTI  #提示OK，开启事务
   set k1 v1 #提示QUEUED，加入队列
   set k2 v2
   get k1
   EXEC #会输出每一个操作的执行结果
   ```

2. 取消事务

   ```shell
   MULTI  #提示OK，开启事务
   set k1 v1 #提示QUEUED，加入队列
   set k2 v2
   get k1
   DISCARD #提示OK，取消事务
   ```

3. 命令本身出现错误

   ```shell
   MULTI  #提示OK，开启事务
   set k1 v1 #提示QUEUED，加入队列
   set k2   #提示error信息：语法错误
   get k1  #仍然提示QUEUED，加入队列
   EXEC  #执行事务失败，提示error信息，所有操作都执行失败
   ```

4. 命令执行出错

   ```shell
   MULTI
   INCR k1 #提示QUEUED，加入队列
   set k3 v3 #提示QUEUED，加入队列
   EXEC #第一条由于k1是字符串无法增长故提示错误信息；第二条执行成功
   ```



## watch监控

### 乐/悲观锁

- 悲观锁(Pessimistic Lock)
  - 每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。
  - 传统的关系型数据库里就用到了很多这种锁机制，如行锁、表锁等，读锁、写锁等，都是在做操作前先上锁
  - 强一致性，但性能下降
- 乐观锁(Optimistic Lock)
  - 每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。
  - 乐观锁适用于多读的应用类型，这样可以提高吞吐量。
  - **乐观锁策略:提交版本必须大于记录当前版本才能执行更新**
- CAS



一旦执行了exec之前加的监控锁都会被取消掉了



### watch

- Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行；
- 通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回 Nullmulti-bulk 应答以通知调用者事务执行失败

案例：

初始化余额、欠款

```shell
set balance 100
set debt 0
#事务
MULTI
decrby balance 30
incrby debt 30
EXEC  #此时balance=70，debt=30
```

无加塞篡改，先监控再开启multi，保证两笔金额变动在同一个事务内

```shell
watch balance
MULTI
decrby balance 10
incrby debt 10
EXEC #此时balance=60，debt=40
```

有加塞篡改：A监控了key，如果B先对key进行了修改，A事务的执行失效。

unwatch：取消watch命令对所有key的监视



